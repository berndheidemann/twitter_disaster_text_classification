{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# https://www.kaggle.com/competitions/nlp-getting-started\n\n!python -m spacy download en_core_web_sm",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n",
      "    return _get_module_details(pkg_main_name, error)\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\errors.py\", line 2, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\compat.py\", line 3, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\config.py\", line 2, in <module>\n",
      "    import confection\n",
      "  File \"C:\\Users\\bernd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\confection\\__init__.py\", line 10, in <module>\n",
      "    from pydantic import BaseModel, create_model, ValidationError, Extra\n",
      "  File \"pydantic\\__init__.py\", line 2, in init pydantic.__init__\n",
      "  File \"pydantic\\dataclasses.py\", line 52, in init pydantic.dataclasses\n",
      "    #   +--- init= parameter\n",
      "ImportError: cannot import name dataclass_transform\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "!git clone https://github.com/berndheidemann/twitter_disaster_text_classification.git",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:01.314377Z",
     "iopub.execute_input": "2023-02-07T06:52:01.314786Z",
     "iopub.status.idle": "2023-02-07T06:52:03.265742Z",
     "shell.execute_reply.started": "2023-02-07T06:52:01.314743Z",
     "shell.execute_reply": "2023-02-07T06:52:03.264320Z"
    },
    "trusted": true
   },
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'twitter_disaster_text_classification' already exists and is not an empty directory.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "path=\"./\"\n",
    "#path=\"/kaggle/working/twitter_disaster_text_classification/\"\n",
    "train_csv=path+\"train.csv\"\n",
    "test_csv=path+\"test.csv\"\n",
    "submission_csv=path+\"sample_submission.csv\"\n",
    "\n",
    "df = pd.read_csv(train_csv)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:03.267830Z",
     "iopub.execute_input": "2023-02-07T06:52:03.268227Z",
     "iopub.status.idle": "2023-02-07T06:52:03.318312Z",
     "shell.execute_reply.started": "2023-02-07T06:52:03.268187Z",
     "shell.execute_reply": "2023-02-07T06:52:03.317336Z"
    },
    "trusted": true
   },
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df[\"keyword\"].fillna(\"None\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": "from torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\ntokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n\n# create iterator from tokenized df\ndef df_iterator_content(df):\n    for _, row in df.iterrows():\n        yield tokenizer(row['text'])\n\nvocab = build_vocab_from_iterator(df_iterator_content(df), specials=[\"<unk>\"], min_freq=5)\nvocab.set_default_index(vocab[\"<unk>\"])\nvocab_size = len(vocab)\nprint(vocab_size)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:03.331601Z",
     "iopub.execute_input": "2023-02-07T06:52:03.332086Z",
     "iopub.status.idle": "2023-02-07T06:52:11.392427Z",
     "shell.execute_reply.started": "2023-02-07T06:52:03.332047Z",
     "shell.execute_reply": "2023-02-07T06:52:11.391213Z"
    },
    "trusted": true
   },
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "def df_iterator_keyword(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield tokenizer(row['keyword'])\n",
    "\n",
    "vocab_keyword = build_vocab_from_iterator(df_iterator_keyword(df), specials=[\"<unk>\"])\n",
    "vocab_keyword.set_default_index(vocab_keyword[\"<unk>\"])\n",
    "vocab_size_keyword = len(vocab_keyword)\n",
    "print(vocab_size_keyword)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TwitterDisasterDataset(Dataset):\n",
    "    def __init__(self, df, word_count=500, vocab_size=10000, train=True):\n",
    "        self.df = df\n",
    "        self.word_count = word_count\n",
    "        self.vocab_size = vocab_size\n",
    "        self.train=train\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        text= self.df.iloc[idx][\"text\"]\n",
    "        text = vocab(tokenizer(text))\n",
    "        if self.train:\n",
    "            y= self.df.iloc[idx][\"target\"]\n",
    "            y = int(y)\n",
    "        if len(text) > self.word_count:\n",
    "            text=text[:self.word_count]\n",
    "        else:\n",
    "            text.extend([0]*(self.word_count-len(text)))\n",
    "        text = torch.tensor(text)\n",
    "        keyword=self.df.iloc[idx][\"keyword\"]\n",
    "        keyword = vocab_keyword(tokenizer(keyword))\n",
    "        keyword = torch.tensor(keyword)\n",
    "\n",
    "        if self.train:\n",
    "            return (text.to(device), keyword.to(device)), torch.tensor(y).to(device)\n",
    "        else:\n",
    "            return (text.to(device), keyword.to(device))\n",
    "\n",
    "twitter_dataset = TwitterDisasterDataset(df, word_count=30, vocab_size=vocab_size)\n",
    "(text, keyword),y=twitter_dataset[23]\n",
    "print(text)\n",
    "print(keyword)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:11.394038Z",
     "iopub.execute_input": "2023-02-07T06:52:11.394739Z",
     "iopub.status.idle": "2023-02-07T06:52:19.341484Z",
     "shell.execute_reply.started": "2023-02-07T06:52:11.394699Z",
     "shell.execute_reply": "2023-02-07T06:52:19.340345Z"
    },
    "trusted": true
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([138,   6,   0, 119,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0])\n",
      "tensor([1])\n",
      "tensor(0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, text_embedding_dim, text_hidden_dim, vocab_size, out_size, word_count=50, dropout=0.2, num_layers=2, keyword_embedding_dim=16, hidden_layer_size=64):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_dim = text_hidden_dim\n",
    "        self.text_embedding_dim=text_embedding_dim\n",
    "        self.text_embeddings = nn.Embedding(vocab_size, text_embedding_dim)\n",
    "        self.keyword_embeddings = nn.Embedding(vocab_size, keyword_embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(text_embedding_dim, text_hidden_dim, batch_first=True, dropout=dropout, num_layers=num_layers)\n",
    "        self.dropout=nn.Dropout(p=dropout)\n",
    "\n",
    "        self.fc_lstm_to_merge = nn.Linear(text_hidden_dim * word_count, keyword_embedding_dim)\n",
    "        self.fc_merge_to_hidden = nn.Linear(keyword_embedding_dim*2, hidden_layer_size)\n",
    "        self.fc_hidden_to_out = nn.Linear(hidden_layer_size, out_size)\n",
    "\n",
    "    def forward(self, text_b, keyword_b, foo=None):\n",
    "        #print(\"xb shape\", xb.shape)\n",
    "        text_embeds = self.text_embeddings(text_b)\n",
    "        #print(\"embeds shape\", text_embeds.shape)\n",
    "        lstm_out, _ = self.lstm(text_embeds)\n",
    "        lstm_out=self.dropout(lstm_out)\n",
    "        #print(\"lstm_out shape\", lstm_out.shape)\n",
    "        lstm_out_view = lstm_out.reshape(text_b.shape[0], -1   )\n",
    "        #print(\"lstm_out_view shape\", lstm_out_view.shape)\n",
    "        lstm_to_merge = self.fc_lstm_to_merge(lstm_out_view)\n",
    "        #print(\"lstm_to_merge shape\", lstm_to_merge.shape)\n",
    "        keyword_embeds = self.keyword_embeddings(keyword_b)\n",
    "        #print(\"keyword_embeds shape\", keyword_embeds.shape)\n",
    "        keyword_embeds_view = keyword_embeds.reshape(text_b.shape[0], -1   )\n",
    "        #print(\"keyword_embeds_view shape\", keyword_embeds_view.shape)\n",
    "        merged = torch.cat((lstm_to_merge, keyword_embeds_view), dim=1)\n",
    "        #print(\"merged shape\", merged.shape)\n",
    "        merged = F.relu(merged)\n",
    "        merged = self.dropout(merged)\n",
    "        #print(\"merge shape\", merge.shape)\n",
    "        hidden = self.fc_merge_to_hidden(merged)\n",
    "        hidden = F.relu(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        output = self.fc_hidden_to_out(hidden)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        #print(\"output shape\", output.shape)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:19.343129Z",
     "iopub.execute_input": "2023-02-07T06:52:19.343504Z",
     "iopub.status.idle": "2023-02-07T06:52:19.353041Z",
     "shell.execute_reply.started": "2023-02-07T06:52:19.343467Z",
     "shell.execute_reply": "2023-02-07T06:52:19.351909Z"
    },
    "trusted": true
   },
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    with torch.no_grad():\n",
    "        for idx, (xb, label) in enumerate(dataloader):\n",
    "            text, keyword = xb\n",
    "            predicted_label = model(text, keyword)\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "            y_pred.extend(predicted_label.argmax(1).cpu().numpy())\n",
    "    return f1_score(y_true, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:19.354784Z",
     "iopub.execute_input": "2023-02-07T06:52:19.355168Z",
     "iopub.status.idle": "2023-02-07T06:52:19.420499Z",
     "shell.execute_reply.started": "2023-02-07T06:52:19.355129Z",
     "shell.execute_reply": "2023-02-07T06:52:19.419546Z"
    },
    "trusted": true
   },
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameter\n",
    "embed_dim = 128\n",
    "num_class = 2\n",
    "hidden_dim = 64\n",
    "word_count = 50\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 0.01  # learning rate\n",
    "scheduler_patience=4\n",
    "scheduler_factor=0.2\n",
    "weight_decay=1e-4\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "dropout=0.7\n",
    "num_layers=2\n",
    "hidden_layer_size=64\n",
    "keyword_embedding_dim=16\n",
    "\n",
    "\n",
    "# check if model works\n",
    "model= MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout, num_layers=num_layers, hidden_layer_size=hidden_layer_size, keyword_embedding_dim=keyword_embedding_dim).to(device)\n",
    "dataset = TwitterDisasterDataset(df, word_count=word_count, vocab_size=vocab_size)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "(text, keyword), yb = next(iter(loader))\n",
    "print(\"yb\", yb)\n",
    "print(\"xb text shape\", text.shape)\n",
    "print(\"xb keyword shape\", keyword.shape)\n",
    "model(text, keyword)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:19.421902Z",
     "iopub.execute_input": "2023-02-07T06:52:19.422601Z",
     "iopub.status.idle": "2023-02-07T06:52:21.300244Z",
     "shell.execute_reply.started": "2023-02-07T06:52:19.422564Z",
     "shell.execute_reply": "2023-02-07T06:52:21.299283Z"
    },
    "trusted": true
   },
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yb tensor([1, 0, 1, 0, 1])\n",
      "xb text shape torch.Size([5, 50])\n",
      "xb keyword shape torch.Size([5, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-1.0398, -0.4362],\n        [-0.6683, -0.7186],\n        [-0.9212, -0.5076],\n        [-0.7961, -0.5998],\n        [-0.6999, -0.6865]], grad_fn=<LogSoftmaxBackward0>)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bernd\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4315: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "C:\\Users\\bernd\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\onnx\\_internal\\jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "C:\\Users\\bernd\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\onnx\\utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "C:\\Users\\bernd\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\onnx\\utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, (text, keyword), \"model.onnx\", input_names=[\"text\", \"keyword\"], output_names=[\"y_hat\"], verbose=True, opset_version=11)\n",
    "\n",
    "# visualize model with netron.app"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# hyperparameter search\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {\n",
    "    \"embed_dim\": [64, 128],\n",
    "    \"hidden_dim\": [64],\n",
    "    \"dropout\": [0.4, 0.7],\n",
    "    \"num_layers\": [2],\n",
    "    \"weight_decay\": [1e-6],\n",
    "    \"LR\": [0.01],\n",
    "    \"BATCH_SIZE\": [128],\n",
    "    \"hidden_layer_size\": [32, 64, 128],\n",
    "    \"keyword_embedding_dim\": [8, 16, 32],\n",
    "    \"word_count\": [50]\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "print(next(iter(param_grid)))\n",
    "print(len(param_grid))"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:21.301603Z",
     "iopub.execute_input": "2023-02-07T06:52:21.302059Z",
     "iopub.status.idle": "2023-02-07T06:52:21.322230Z",
     "shell.execute_reply.started": "2023-02-07T06:52:21.302015Z",
     "shell.execute_reply": "2023-02-07T06:52:21.321064Z"
    },
    "trusted": true
   },
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50}\n",
      "36\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def grid_search():\n",
    "\n",
    "    params_count={}\n",
    "    for params in param_grid:\n",
    "        for key, value in params.items():\n",
    "            param_str=key+\":\"+str(value)\n",
    "            if param_str not in params_count:\n",
    "                params_count[param_str]=1\n",
    "            else:\n",
    "                params_count[param_str]+=1\n",
    "    EPOCHS=10\n",
    "\n",
    "    # set all random seeds\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    (gridsearch_portion_idx, test_idx) = next(iter(k_fold.split(df[\"text\"], df[\"target\"])))\n",
    "    grid_test_df=df.iloc[test_idx]\n",
    "    gridsearch_df=df.iloc[gridsearch_portion_idx]\n",
    "    test_dataset=TwitterDisasterDataset(grid_test_df, word_count=word_count, vocab_size=vocab_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    k_fold_iter=iter(k_fold.split(gridsearch_df[\"text\"], gridsearch_df[\"target\"]))\n",
    "    (base_idx, split_portion_idx)=next(k_fold_iter)\n",
    "    base_df = df.iloc[base_idx]\n",
    "    split_portion_df = df.iloc[split_portion_idx]\n",
    "    train_dataset = TwitterDisasterDataset(split_portion_df, word_count=word_count, vocab_size=vocab_size)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    i=0\n",
    "    best_params_val=0\n",
    "    best_params=None\n",
    "    params_results={}\n",
    "    for params in param_grid:\n",
    "        i+=1\n",
    "        model = MyLSTM(params[\"embed_dim\"], params[\"hidden_dim\"], vocab_size, num_class, word_count=word_count, dropout=params[\"dropout\"], num_layers=params[\"num_layers\"]).to(device)\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params[\"LR\"], weight_decay=params[\"weight_decay\"])\n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            for idx, (xb, label) in enumerate(train_dataloader):\n",
    "                text, keyword = xb\n",
    "                predicted_label = model(text, keyword)\n",
    "                loss = loss_func(predicted_label, label)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        test_f1 = evaluate(model, test_dataloader)\n",
    "        print(f\"{i} / {len(param_grid)} params {params} Test f1 {test_f1}\")\n",
    "        with open(\"results.txt\", \"a\") as f:\n",
    "            f.write(f\"{i}: params {params} test f1 {test_f1} \\n\")\n",
    "        if test_f1 > best_params_val:\n",
    "            best_params_val = test_f1\n",
    "            best_params = params\n",
    "        for key, value in params.items():\n",
    "            param_str=key+\":\"+str(value)\n",
    "            if param_str not in params_results:\n",
    "                params_results[param_str]=test_f1\n",
    "            else:\n",
    "                params_results[param_str]+=test_f1\n",
    "\n",
    "    for key, value in params_results.items():\n",
    "        params_results[key]=params_results[key]/params_count[key]\n",
    "    return best_params, best_params_val, params_results\n",
    "\n",
    "best_params, best_params_val, params_results = grid_search()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:21.323790Z",
     "iopub.execute_input": "2023-02-07T06:52:21.324422Z",
     "iopub.status.idle": "2023-02-07T06:52:21.338970Z",
     "shell.execute_reply.started": "2023-02-07T06:52:21.324383Z",
     "shell.execute_reply": "2023-02-07T06:52:21.337844Z"
    },
    "trusted": true
   },
   "execution_count": 99,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[99], line 67\u001B[0m\n\u001B[0;32m     64\u001B[0m         params_results[key]\u001B[38;5;241m=\u001B[39mparams_results[key]\u001B[38;5;241m/\u001B[39mparams_count[key]\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m best_params, best_params_val, params_results\n\u001B[1;32m---> 67\u001B[0m best_params, best_params_val, params_results \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[99], line 44\u001B[0m, in \u001B[0;36mgrid_search\u001B[1;34m()\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, (xb, label) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[0;32m     43\u001B[0m     text, keyword \u001B[38;5;241m=\u001B[39m xb\n\u001B[1;32m---> 44\u001B[0m     predicted_label \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeyword\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_func(predicted_label, label)\n\u001B[0;32m     46\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[88], line 29\u001B[0m, in \u001B[0;36mMyLSTM.forward\u001B[1;34m(self, text_b, keyword_b, foo)\u001B[0m\n\u001B[0;32m     27\u001B[0m text_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_embeddings(text_b)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m#print(\"embeds shape\", text_embeds.shape)\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m lstm_out, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_embeds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m lstm_out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(lstm_out)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m#print(\"lstm_out shape\", lstm_out.shape)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    772\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[0;32m    773\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 774\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    775\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    776\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    777\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[0;32m    778\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "hyperparams = {'BATCH_SIZE': 256,\n",
    " 'LR': 0.01,\n",
    " 'dropout': 0.4,\n",
    " 'embed_dim': 64,\n",
    " 'hidden_dim': 64,\n",
    " 'num_layers': 2,\n",
    " 'weight_decay': 0.0001}\n",
    "\n",
    "BATCH_SIZE=hyperparams[\"BATCH_SIZE\"]\n",
    "LR = hyperparams[\"LR\"]\n",
    "embed_dim = hyperparams[\"embed_dim\"]\n",
    "hidden_dim = hyperparams[\"hidden_dim\"]\n",
    "num_layers = hyperparams[\"num_layers\"]\n",
    "weight_decay = hyperparams[\"weight_decay\"]\n",
    "word_count = 30\n",
    "EPOCHS = 1\n",
    "scheduler_patience=4\n",
    "scheduler_factor=0.2"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:21.371009Z",
     "iopub.execute_input": "2023-02-07T06:52:21.371373Z",
     "iopub.status.idle": "2023-02-07T06:52:21.378687Z",
     "shell.execute_reply.started": "2023-02-07T06:52:21.371345Z",
     "shell.execute_reply": "2023-02-07T06:52:21.377456Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "\n# create train and valid dataset\ntrain_dataset, valid_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n\n# import torch DataLoader\nfrom torch.utils.data import DataLoader\n\nmodel = MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout).to(device)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=weight_decay)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_step_size, gamma=lr_gamma)   # every 10 epochs, LR is multiplied by 0.7\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=scheduler_factor, patience=scheduler_patience)\n\n",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:21.380284Z",
     "iopub.execute_input": "2023-02-07T06:52:21.380912Z",
     "iopub.status.idle": "2023-02-07T06:52:21.395990Z",
     "shell.execute_reply.started": "2023-02-07T06:52:21.380875Z",
     "shell.execute_reply": "2023-02-07T06:52:21.395029Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "total_accu = None\n",
    "train_accus=[]\n",
    "valid_accus=[]\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    for idx, (xb, label) in enumerate(train_dataloader):\n",
    "        text, keyword = xb\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, keyword)\n",
    "        loss = loss_func(predicted_label, label)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "    accu_train = evaluate(model, train_dataloader)\n",
    "    accu_valid = evaluate(model, valid_dataloader)\n",
    "    train_accus.append(accu_train)\n",
    "    valid_accus.append(accu_valid)\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | train f1 {:8.3f} | valid f1 {:8.3f} | lr: {:1.5f}'.format(\n",
    "        epoch,\n",
    "        time.time() - epoch_start_time,\n",
    "        accu_train,\n",
    "        accu_valid,\n",
    "        optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    scheduler.step(accu_valid) # learning rate scheduler after each epoch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_accus, label='train_accu')\n",
    "plt.plot(valid_accus, label='valid_accu')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:52:21.397656Z",
     "iopub.execute_input": "2023-02-07T06:52:21.398038Z",
     "iopub.status.idle": "2023-02-07T06:54:06.364280Z",
     "shell.execute_reply.started": "2023-02-07T06:52:21.398005Z",
     "shell.execute_reply": "2023-02-07T06:54:06.363292Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 43.79s | train f1    0.633 | valid f1    0.602 | lr: 0.01000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "df_test = pd.read_csv(test_csv)\ndf_test.head()",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:54:06.366115Z",
     "iopub.execute_input": "2023-02-07T06:54:06.367048Z",
     "iopub.status.idle": "2023-02-07T06:54:06.391397Z",
     "shell.execute_reply.started": "2023-02-07T06:54:06.367004Z",
     "shell.execute_reply": "2023-02-07T06:54:06.390436Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "execution_count": 18,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_dataset = TwitterDisasterDataset(df_test, word_count=word_count, vocab_size=vocab_size, train=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "predictions=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, xb in enumerate(test_dataloader):\n",
    "        text, keyword = xb\n",
    "        predicted_label = model(text, keyword)\n",
    "        predictions.append(predicted_label.argmax(1).cpu().numpy())\n",
    "        \n",
    "\n",
    "predictions=np.concatenate(predictions)\n",
    "print(predictions.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:54:06.392595Z",
     "iopub.execute_input": "2023-02-07T06:54:06.393445Z",
     "iopub.status.idle": "2023-02-07T06:54:07.989447Z",
     "shell.execute_reply.started": "2023-02-07T06:54:06.393403Z",
     "shell.execute_reply": "2023-02-07T06:54:07.988289Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": "(3263,)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "len(predictions)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-07T06:54:07.990936Z",
     "iopub.execute_input": "2023-02-07T06:54:07.991414Z",
     "iopub.status.idle": "2023-02-07T06:54:07.998209Z",
     "shell.execute_reply.started": "2023-02-07T06:54:07.991374Z",
     "shell.execute_reply": "2023-02-07T06:54:07.997173Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "execution_count": 20,
     "output_type": "execute_result",
     "data": {
      "text/plain": "3263"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "df_submission = pd.read_csv(submission_csv)\ndf_submission.head()",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:54:07.999874Z",
     "iopub.execute_input": "2023-02-07T06:54:08.000569Z",
     "iopub.status.idle": "2023-02-07T06:54:08.016134Z",
     "shell.execute_reply.started": "2023-02-07T06:54:08.000523Z",
     "shell.execute_reply": "2023-02-07T06:54:08.014912Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": [
    {
     "execution_count": 21,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "df_submission[\"target\"] = predictions\ndf_submission.head()",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:54:08.017956Z",
     "iopub.execute_input": "2023-02-07T06:54:08.018357Z",
     "iopub.status.idle": "2023-02-07T06:54:08.030100Z",
     "shell.execute_reply.started": "2023-02-07T06:54:08.018321Z",
     "shell.execute_reply": "2023-02-07T06:54:08.028748Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [
    {
     "execution_count": 22,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       0\n4  11       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "df_submission.to_csv(\"submission.csv\", index=False)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:54:08.032254Z",
     "iopub.execute_input": "2023-02-07T06:54:08.032715Z",
     "iopub.status.idle": "2023-02-07T06:54:08.044333Z",
     "shell.execute_reply.started": "2023-02-07T06:54:08.032659Z",
     "shell.execute_reply": "2023-02-07T06:54:08.043330Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_submission.describe()",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-07T06:54:08.045909Z",
     "iopub.execute_input": "2023-02-07T06:54:08.046555Z",
     "iopub.status.idle": "2023-02-07T06:54:08.073038Z",
     "shell.execute_reply.started": "2023-02-07T06:54:08.046516Z",
     "shell.execute_reply": "2023-02-07T06:54:08.071293Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": [
    {
     "execution_count": 24,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 id       target\ncount   3263.000000  3263.000000\nmean    5427.152927     0.393196\nstd     3146.427221     0.488535\nmin        0.000000     0.000000\n25%     2683.000000     0.000000\n50%     5500.000000     0.000000\n75%     8176.000000     1.000000\nmax    10875.000000     1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3263.000000</td>\n      <td>3263.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5427.152927</td>\n      <td>0.393196</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3146.427221</td>\n      <td>0.488535</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2683.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5500.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8176.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10875.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
