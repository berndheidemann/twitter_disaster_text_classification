{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.model_selection import StratifiedKFold\nimport time\nimport matplotlib.pyplot as plt\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-08T13:49:03.922281Z","iopub.execute_input":"2023-02-08T13:49:03.922637Z","iopub.status.idle":"2023-02-08T13:49:03.929798Z","shell.execute_reply.started":"2023-02-08T13:49:03.922608Z","shell.execute_reply":"2023-02-08T13:49:03.928847Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/competitions/nlp-getting-started\n\n!python -m spacy download en_core_web_sm","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:03.941589Z","iopub.execute_input":"2023-02-08T13:49:03.942414Z","iopub.status.idle":"2023-02-08T13:49:23.395197Z","shell.execute_reply.started":"2023-02-08T13:49:03.942374Z","shell.execute_reply":"2023-02-08T13:49:23.393922Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.3.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.3.0) (3.3.2)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.9)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (59.8.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.9)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.8)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.1)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.5)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.4)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.3.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (23.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/berndheidemann/twitter_disaster_text_classification.git","metadata":{"execution":{"iopub.status.busy":"2023-02-08T13:49:23.398631Z","iopub.execute_input":"2023-02-08T13:49:23.399397Z","iopub.status.idle":"2023-02-08T13:49:24.457646Z","shell.execute_reply.started":"2023-02-08T13:49:23.399362Z","shell.execute_reply":"2023-02-08T13:49:24.456452Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"fatal: destination path 'twitter_disaster_text_classification' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#path=\"./\"\npath=\"/kaggle/working/twitter_disaster_text_classification/\"\ntrain_csv=path+\"train.csv\"\ntest_csv=path+\"test.csv\"\nsubmission_csv=path+\"sample_submission.csv\"\n\ndf = pd.read_csv(train_csv)\ndf.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:24.460001Z","iopub.execute_input":"2023-02-08T13:49:24.460412Z","iopub.status.idle":"2023-02-08T13:49:24.494273Z","shell.execute_reply.started":"2023-02-08T13:49:24.460373Z","shell.execute_reply":"2023-02-08T13:49:24.493117Z"},"trusted":true},"execution_count":119,"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"keyword\"].fillna(\"None\", inplace=True)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:24.497052Z","iopub.execute_input":"2023-02-08T13:49:24.497504Z","iopub.status.idle":"2023-02-08T13:49:24.503741Z","shell.execute_reply.started":"2023-02-08T13:49:24.497469Z","shell.execute_reply":"2023-02-08T13:49:24.502640Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"\ntokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n\n# create iterator from tokenized df\ndef df_iterator_content(df):\n    for _, row in df.iterrows():\n        yield tokenizer(row['text'])\n\nvocab = build_vocab_from_iterator(df_iterator_content(df), specials=[\"<unk>\"], min_freq=5)\nvocab.set_default_index(vocab[\"<unk>\"])\nvocab_size = len(vocab)\nprint(vocab_size)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:24.505108Z","iopub.execute_input":"2023-02-08T13:49:24.506086Z","iopub.status.idle":"2023-02-08T13:49:27.896651Z","shell.execute_reply.started":"2023-02-08T13:49:24.506049Z","shell.execute_reply":"2023-02-08T13:49:27.895529Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"3240\n","output_type":"stream"}]},{"cell_type":"code","source":"def df_iterator_keyword(df):\n    for _, row in df.iterrows():\n        yield tokenizer(row['keyword'])\n\nvocab_keyword = build_vocab_from_iterator(df_iterator_keyword(df), specials=[\"<unk>\"])\nvocab_keyword.set_default_index(vocab_keyword[\"<unk>\"])\nvocab_size_keyword = len(vocab_keyword)\nprint(vocab_size_keyword)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:27.898246Z","iopub.execute_input":"2023-02-08T13:49:27.898851Z","iopub.status.idle":"2023-02-08T13:49:28.502868Z","shell.execute_reply.started":"2023-02-08T13:49:27.898812Z","shell.execute_reply":"2023-02-08T13:49:28.501788Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"223\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass TwitterDisasterDataset(Dataset):\n    def __init__(self, df, word_count=500, vocab_size=10000, train=True):\n        self.df = df\n        self.word_count = word_count\n        self.vocab_size = vocab_size\n        self.train=train\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        text= self.df.iloc[idx][\"text\"]\n        text = vocab(tokenizer(text))\n        if self.train:\n            y= self.df.iloc[idx][\"target\"]\n            y = int(y)\n        if len(text) > self.word_count:\n            text=text[:self.word_count]\n        else:\n            text.extend([0]*(self.word_count-len(text)))\n        text = torch.tensor(text)\n        keyword=self.df.iloc[idx][\"keyword\"]\n        keyword = vocab_keyword(tokenizer(keyword))\n        keyword = torch.tensor(keyword)\n\n        if self.train:\n            return (text.to(device), keyword.to(device)), torch.tensor(y).to(device)\n        else:\n            return (text.to(device), keyword.to(device))\n\ntwitter_dataset = TwitterDisasterDataset(df, word_count=30, vocab_size=vocab_size)\n(text, keyword),y=twitter_dataset[23]\nprint(text)\nprint(keyword)\nprint(y)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:28.504678Z","iopub.execute_input":"2023-02-08T13:49:28.505062Z","iopub.status.idle":"2023-02-08T13:49:28.519832Z","shell.execute_reply.started":"2023-02-08T13:49:28.505026Z","shell.execute_reply":"2023-02-08T13:49:28.518761Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"tensor([138,   6,   0, 119,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0], device='cuda:0')\ntensor([1], device='cuda:0')\ntensor(0, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntorch.manual_seed(1)\n\nclass MyLSTM(nn.Module):\n\n    def __init__(self, text_embedding_dim, text_hidden_dim, vocab_size, out_size, word_count=50, dropout=0.2, num_layers=2, keyword_embedding_dim=16, hidden_layer_size=64):\n        super(MyLSTM, self).__init__()\n        self.hidden_dim = text_hidden_dim\n        self.text_embedding_dim=text_embedding_dim\n        self.text_embeddings = nn.Embedding(vocab_size, text_embedding_dim)\n        self.keyword_embeddings = nn.Embedding(vocab_size, keyword_embedding_dim)\n\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.\n        self.lstm = nn.LSTM(text_embedding_dim, text_hidden_dim, batch_first=True, dropout=dropout, num_layers=num_layers)\n        self.dropout=nn.Dropout(p=dropout)\n\n        self.fc_lstm_to_merge = nn.Linear(text_hidden_dim * word_count, keyword_embedding_dim)\n        self.bn1 = nn.BatchNorm1d(keyword_embedding_dim*2)\n        self.fc_merge_to_hidden = nn.Linear(keyword_embedding_dim*2, hidden_layer_size)\n        self.bn2 = nn.BatchNorm1d(hidden_layer_size)\n        self.fc_hidden_to_out = nn.Linear(hidden_layer_size, out_size)\n\n    def forward(self, text_b, keyword_b, foo=None):\n        #print(\"xb shape\", xb.shape)\n        text_embeds = self.text_embeddings(text_b)\n        #print(\"embeds shape\", text_embeds.shape)\n        lstm_out, _ = self.lstm(text_embeds)\n        lstm_out=self.dropout(lstm_out)\n        #print(\"lstm_out shape\", lstm_out.shape)\n        lstm_out_view = lstm_out.reshape(text_b.shape[0], -1   )\n        #print(\"lstm_out_view shape\", lstm_out_view.shape)\n        lstm_to_merge = self.fc_lstm_to_merge(lstm_out_view)\n        #print(\"lstm_to_merge shape\", lstm_to_merge.shape)\n        keyword_embeds = self.keyword_embeddings(keyword_b)\n        #print(\"keyword_embeds shape\", keyword_embeds.shape)\n        keyword_embeds_view = keyword_embeds.reshape(text_b.shape[0], -1   )\n        #print(\"keyword_embeds_view shape\", keyword_embeds_view.shape)\n        merged = torch.cat((lstm_to_merge, keyword_embeds_view), dim=1)\n        #print(\"merged shape\", merged.shape)\n        merged = self.bn1(merged)\n        merged = F.relu(merged)\n        merged = self.dropout(merged)\n        #print(\"merge shape\", merge.shape)\n        hidden = self.fc_merge_to_hidden(merged)\n        hidden = self.bn2(hidden)\n        hidden = F.relu(hidden)\n        hidden = self.dropout(hidden)\n        output = self.fc_hidden_to_out(hidden)\n        output = F.log_softmax(output, dim=1)\n        #print(\"output shape\", output.shape)\n        return output","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:28.521567Z","iopub.execute_input":"2023-02-08T13:49:28.522242Z","iopub.status.idle":"2023-02-08T13:49:28.535995Z","shell.execute_reply.started":"2023-02-08T13:49:28.522203Z","shell.execute_reply":"2023-02-08T13:49:28.534992Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"\ndef evaluate(model, dataloader):\n    model.eval()\n    y_true=[]\n    y_pred=[]\n    with torch.no_grad():\n        for idx, (xb, label) in enumerate(dataloader):\n            text, keyword = xb\n            predicted_label = model(text, keyword)\n            y_true.extend(label.cpu().numpy())\n            y_pred.extend(predicted_label.argmax(1).cpu().numpy())\n    return f1_score(y_true, y_pred)\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:28.537292Z","iopub.execute_input":"2023-02-08T13:49:28.537767Z","iopub.status.idle":"2023-02-08T13:49:28.551969Z","shell.execute_reply.started":"2023-02-08T13:49:28.537732Z","shell.execute_reply":"2023-02-08T13:49:28.550976Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter\nembed_dim = 128\nnum_class = 2\nhidden_dim = 64\nword_count = 50\nEPOCHS = 10 # epoch\nLR = 0.01  # learning rate\nscheduler_patience=4\nscheduler_factor=0.2\nweight_decay=1e-4\nBATCH_SIZE = 64 # batch size for training\ndropout=0.7\nnum_layers=2\nhidden_layer_size=64\nkeyword_embedding_dim=16\n\n\n# check if model works\nmodel= MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout, num_layers=num_layers, hidden_layer_size=hidden_layer_size, keyword_embedding_dim=keyword_embedding_dim).to(device)\ndataset = TwitterDisasterDataset(df, word_count=word_count, vocab_size=vocab_size)\nloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n\n(text, keyword), yb = next(iter(loader))\nprint(\"yb\", yb)\nprint(\"xb text shape\", text.shape)\nprint(\"xb keyword shape\", keyword.shape)\nmodel(text, keyword)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:28.556308Z","iopub.execute_input":"2023-02-08T13:49:28.556560Z","iopub.status.idle":"2023-02-08T13:49:28.588705Z","shell.execute_reply.started":"2023-02-08T13:49:28.556537Z","shell.execute_reply":"2023-02-08T13:49:28.587564Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"yb tensor([1, 0, 0, 0, 1], device='cuda:0')\nxb text shape torch.Size([5, 50])\nxb keyword shape torch.Size([5, 1])\n","output_type":"stream"},{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"tensor([[-1.0874, -0.4111],\n        [-1.1631, -0.3747],\n        [-0.1508, -1.9664],\n        [-1.3133, -0.3132],\n        [-1.2385, -0.3423]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# torch.onnx.export(model, (text, keyword), \"model.onnx\", input_names=[\"text\", \"keyword\"], output_names=[\"y_hat\"], verbose=True, opset_version=11)\n\n# visualize model with netron.app","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:28.590321Z","iopub.execute_input":"2023-02-08T13:49:28.590686Z","iopub.status.idle":"2023-02-08T13:49:28.596225Z","shell.execute_reply.started":"2023-02-08T13:49:28.590652Z","shell.execute_reply":"2023-02-08T13:49:28.594904Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"# hyperparameter search\n\nparam_grid = {\n    \"embed_dim\": [64, 128],\n    \"hidden_dim\": [64],\n    \"dropout\": [0.4, 0.7],\n    \"num_layers\": [2],\n    \"weight_decay\": [1e-6],\n    \"LR\": [0.01],\n    \"BATCH_SIZE\": [128],\n    \"hidden_layer_size\": [32, 64, 128],\n    \"keyword_embedding_dim\": [8, 16, 32],\n    \"word_count\": [50]\n}\n\nparam_grid = ParameterGrid(param_grid)\nprint(next(iter(param_grid)))\nprint(len(param_grid))","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:28.597872Z","iopub.execute_input":"2023-02-08T13:49:28.598487Z","iopub.status.idle":"2023-02-08T13:49:28.610873Z","shell.execute_reply.started":"2023-02-08T13:49:28.598416Z","shell.execute_reply":"2023-02-08T13:49:28.610009Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stdout","text":"{'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50}\n36\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef grid_search():\n\n    params_count={}\n    for params in param_grid:\n        for key, value in params.items():\n            param_str=key+\":\"+str(value)\n            if param_str not in params_count:\n                params_count[param_str]=1\n            else:\n                params_count[param_str]+=1\n    EPOCHS=10\n\n    # set all random seeds\n    torch.manual_seed(1)\n    np.random.seed(1)\n\n    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    (gridsearch_portion_idx, test_idx) = next(iter(k_fold.split(df[\"text\"], df[\"target\"])))\n    grid_test_df=df.iloc[test_idx]\n    gridsearch_df=df.iloc[gridsearch_portion_idx]\n    test_dataset=TwitterDisasterDataset(grid_test_df, word_count=word_count, vocab_size=vocab_size)\n    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    k_fold_iter=iter(k_fold.split(gridsearch_df[\"text\"], gridsearch_df[\"target\"]))\n    (base_idx, split_portion_idx)=next(k_fold_iter)\n    base_df = df.iloc[base_idx]\n    split_portion_df = df.iloc[split_portion_idx]\n    train_dataset = TwitterDisasterDataset(split_portion_df, word_count=word_count, vocab_size=vocab_size)\n    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n    i=0\n    best_params_val=0\n    best_params=None\n    params_results={}\n    for params in param_grid:\n        i+=1\n        model = MyLSTM(params[\"embed_dim\"], params[\"hidden_dim\"], vocab_size, num_class, word_count=word_count, dropout=params[\"dropout\"], num_layers=params[\"num_layers\"]).to(device)\n        loss_func = torch.nn.CrossEntropyLoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=params[\"LR\"], weight_decay=params[\"weight_decay\"])\n        for epoch in range(EPOCHS):\n            model.train()\n            for idx, (xb, label) in enumerate(train_dataloader):\n                text, keyword = xb\n                predicted_label = model(text, keyword)\n                loss = loss_func(predicted_label, label)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        test_f1 = evaluate(model, test_dataloader)\n        print(f\"{i} / {len(param_grid)} params {params} Test f1 {test_f1}\")\n        with open(\"results.txt\", \"a\") as f:\n            f.write(f\"{i}: params {params} test f1 {test_f1} \\n\")\n        if test_f1 > best_params_val:\n            best_params_val = test_f1\n            best_params = params\n        for key, value in params.items():\n            param_str=key+\":\"+str(value)\n            if param_str not in params_results:\n                params_results[param_str]=test_f1\n            else:\n                params_results[param_str]+=test_f1\n\n    for key, value in params_results.items():\n        params_results[key]=params_results[key]/params_count[key]\n    return best_params, best_params_val, params_results\n\nbest_params, best_params_val, params_results = grid_search()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:49:28.613366Z","iopub.execute_input":"2023-02-08T13:49:28.613899Z","iopub.status.idle":"2023-02-08T13:53:22.722058Z","shell.execute_reply.started":"2023-02-08T13:49:28.613856Z","shell.execute_reply":"2023-02-08T13:53:22.720728Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"1 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6179159049360147\n2 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6687306501547987\n3 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6578512396694215\n4 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5917602996254682\n5 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6414414414414414\n6 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6898638426626323\n7 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6384479717813052\n8 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6547811993517019\n9 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6624405705229794\n10 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.652317880794702\n11 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6802325581395349\n12 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6838709677419356\n13 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.669811320754717\n14 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6622734761120264\n15 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6878787878787879\n16 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6790299572039943\n17 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6687898089171973\n18 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.652317880794702\n19 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.006079027355623101\n20 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6318471337579618\n21 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.06470588235294118\n22 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.2564102564102564\n23 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.10826210826210826\n24 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.08620689655172414\n25 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.10644257703081232\n26 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.44155844155844154\n27 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.018072289156626505\n28 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.04747774480712166\n29 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.09714285714285713\n30 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 32, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.006079027355623101\n31 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5103189493433395\n32 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6666666666666666\n33 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.03582089552238806\n34 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 8, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5669291338582678\n35 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 16, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.07602339181286549\n36 / 36 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 128, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params, best_params_val","metadata":{"execution":{"iopub.status.busy":"2023-02-08T13:53:22.724252Z","iopub.execute_input":"2023-02-08T13:53:22.724727Z","iopub.status.idle":"2023-02-08T13:53:22.735058Z","shell.execute_reply.started":"2023-02-08T13:53:22.724679Z","shell.execute_reply":"2023-02-08T13:53:22.733637Z"},"trusted":true},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"({'BATCH_SIZE': 128,\n  'LR': 0.01,\n  'dropout': 0.4,\n  'embed_dim': 64,\n  'hidden_dim': 64,\n  'hidden_layer_size': 64,\n  'keyword_embedding_dim': 32,\n  'num_layers': 2,\n  'weight_decay': 1e-06,\n  'word_count': 50},\n 0.6898638426626323)"},"metadata":{}}]},{"cell_type":"code","source":"params_results","metadata":{"execution":{"iopub.status.busy":"2023-02-08T13:53:22.736837Z","iopub.execute_input":"2023-02-08T13:53:22.738136Z","iopub.status.idle":"2023-02-08T13:53:22.746881Z","shell.execute_reply.started":"2023-02-08T13:53:22.738064Z","shell.execute_reply":"2023-02-08T13:53:22.745572Z"},"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"{'BATCH_SIZE:128': 0.4329388621508051,\n 'LR:0.01': 0.4329388621508051,\n 'dropout:0.4': 0.6588753199157422,\n 'embed_dim:64': 0.4190454295879033,\n 'hidden_dim:64': 0.4329388621508051,\n 'hidden_layer_size:32': 0.40118757285071127,\n 'keyword_embedding_dim:8': 0.4452450853251351,\n 'num_layers:2': 0.4329388621508051,\n 'weight_decay:1e-06': 0.4329388621508051,\n 'word_count:50': 0.4329388621508051,\n 'keyword_embedding_dim:16': 0.4998124777764669,\n 'keyword_embedding_dim:32': 0.3537590233508135,\n 'hidden_layer_size:64': 0.46722624510262983,\n 'hidden_layer_size:128': 0.43040276849907455,\n 'embed_dim:128': 0.44683229471370706,\n 'dropout:0.7': 0.20700240438586806}"},"metadata":{}}]},{"cell_type":"code","source":"hyperparams = {'BATCH_SIZE': 128,\n  'LR': 0.01,\n  'dropout': 0.4,\n  'embed_dim': 64,\n  'hidden_dim': 64,\n  'hidden_layer_size': 64,\n  'keyword_embedding_dim': 32,\n  'num_layers': 2,\n  'weight_decay': 1e-06,\n  'word_count': 50}\n\n\nBATCH_SIZE=hyperparams[\"BATCH_SIZE\"]\nLR = hyperparams[\"LR\"]\nembed_dim = hyperparams[\"embed_dim\"]\nhidden_dim = hyperparams[\"hidden_dim\"]\nnum_layers = hyperparams[\"num_layers\"]\nweight_decay = hyperparams[\"weight_decay\"]\nword_count = hyperparams[\"word_count\"]\nhidden_layer_size=hyperparams[\"hidden_layer_size\"]\nkeyword_embedding_dim=hyperparams[\"keyword_embedding_dim\"]\nEPOCHS = 5\nscheduler_patience=4\nscheduler_factor=0.2","metadata":{"execution":{"iopub.status.busy":"2023-02-08T13:58:57.714001Z","iopub.execute_input":"2023-02-08T13:58:57.714367Z","iopub.status.idle":"2023-02-08T13:58:57.721453Z","shell.execute_reply.started":"2023-02-08T13:58:57.714336Z","shell.execute_reply":"2023-02-08T13:58:57.720484Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"\n# create train and valid dataset\ntrain_dataset, valid_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n\n# import torch DataLoader\nfrom torch.utils.data import DataLoader\n\nmodel = MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout, keyword_embedding_dim=keyword_embedding_dim, hidden_layer_size=hidden_layer_size ).to(device)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=weight_decay)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_step_size, gamma=lr_gamma)   # every 10 epochs, LR is multiplied by 0.7\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=scheduler_factor, patience=scheduler_patience)\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:58:58.083044Z","iopub.execute_input":"2023-02-08T13:58:58.084188Z","iopub.status.idle":"2023-02-08T13:58:58.102337Z","shell.execute_reply.started":"2023-02-08T13:58:58.084139Z","shell.execute_reply":"2023-02-08T13:58:58.101394Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"total_accu = None\ntrain_accus=[]\nvalid_accus=[]\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n\n    model.train()\n    total_acc, total_count = 0, 0\n\n    for idx, (xb, label) in enumerate(train_dataloader):\n        text, keyword = xb\n        optimizer.zero_grad()\n        predicted_label = model(text, keyword)\n        loss = loss_func(predicted_label, label)\n        loss.backward()\n        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n\n    accu_train = evaluate(model, train_dataloader)\n    accu_valid = evaluate(model, valid_dataloader)\n    train_accus.append(accu_train)\n    valid_accus.append(accu_valid)\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | train f1 {:8.3f} | valid f1 {:8.3f} | lr: {:1.5f}'.format(\n        epoch,\n        time.time() - epoch_start_time,\n        accu_train,\n        accu_valid,\n        optimizer.param_groups[0]['lr']))\n\n    scheduler.step(accu_valid) # learning rate scheduler after each epoch\n\nplt.plot(train_accus, label='train_accu')\nplt.plot(valid_accus, label='valid_accu')\nplt.legend()\nplt.show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T13:58:58.426175Z","iopub.execute_input":"2023-02-08T13:58:58.426586Z","iopub.status.idle":"2023-02-08T13:59:50.901993Z","shell.execute_reply.started":"2023-02-08T13:58:58.426551Z","shell.execute_reply":"2023-02-08T13:59:50.899991Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"-----------------------------------------------------------\n| end of epoch   1 | time: 10.90s | train f1    0.000 | valid f1    0.000 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   2 | time: 10.25s | train f1    0.316 | valid f1    0.311 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   3 | time: 10.24s | train f1    0.700 | valid f1    0.660 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   4 | time: 10.68s | train f1    0.822 | valid f1    0.733 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   5 | time: 10.18s | train f1    0.848 | valid f1    0.743 | lr: 0.01000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"df_test = pd.read_csv(test_csv)\ndf_test[\"keyword\"].fillna(\"None\", inplace=True)\ndf_test.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T14:01:11.284567Z","iopub.execute_input":"2023-02-08T14:01:11.284977Z","iopub.status.idle":"2023-02-08T14:01:11.309757Z","shell.execute_reply.started":"2023-02-08T14:01:11.284943Z","shell.execute_reply":"2023-02-08T14:01:11.308731Z"},"trusted":true},"execution_count":154,"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0    None      NaN                 Just happened a terrible car crash\n1   2    None      NaN  Heard about #earthquake is different cities, s...\n2   3    None      NaN  there is a forest fire at spot pond, geese are...\n3   9    None      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11    None      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset = TwitterDisasterDataset(df_test, word_count=word_count, vocab_size=vocab_size, train=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n\npredictions=[]\nmodel.eval()\nwith torch.no_grad():\n    for idx, xb in enumerate(test_dataloader):\n        text, keyword = xb\n        predicted_label = model(text, keyword)\n        predictions.append(predicted_label.argmax(1).cpu().numpy())\n        \n\npredictions=np.concatenate(predictions)\nprint(predictions.shape)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T14:01:11.566107Z","iopub.execute_input":"2023-02-08T14:01:11.566506Z","iopub.status.idle":"2023-02-08T14:01:13.482483Z","shell.execute_reply.started":"2023-02-08T14:01:11.566475Z","shell.execute_reply":"2023-02-08T14:01:13.481472Z"},"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"(3263,)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_submission = pd.read_csv(submission_csv)\ndf_submission[\"target\"] = predictions\ndf_submission.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T14:01:13.487287Z","iopub.execute_input":"2023-02-08T14:01:13.489635Z","iopub.status.idle":"2023-02-08T14:01:13.506932Z","shell.execute_reply.started":"2023-02-08T14:01:13.489592Z","shell.execute_reply":"2023-02-08T14:01:13.505846Z"},"trusted":true},"execution_count":156,"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       1\n1   2       0\n2   3       1\n3   9       1\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_submission.to_csv(\"submission.csv\", index=False)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-08T14:01:13.511395Z","iopub.execute_input":"2023-02-08T14:01:13.513669Z","iopub.status.idle":"2023-02-08T14:01:13.528036Z","shell.execute_reply.started":"2023-02-08T14:01:13.513629Z","shell.execute_reply":"2023-02-08T14:01:13.526919Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}