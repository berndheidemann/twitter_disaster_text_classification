{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# https://www.kaggle.com/competitions/nlp-getting-started\n",
    "\n",
    "# !python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T12:06:31.162530Z",
     "iopub.execute_input": "2023-02-06T12:06:31.163081Z",
     "iopub.status.idle": "2023-02-06T12:06:46.902112Z",
     "shell.execute_reply.started": "2023-02-06T12:06:31.163037Z",
     "shell.execute_reply": "2023-02-06T12:06:46.900561Z"
    },
    "trusted": true
   },
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting en-core-web-sm==3.3.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m69.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n\u001B[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.3.0) (3.3.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.4)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.9)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.3.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.8)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (59.8.0)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (23.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.12.7)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.0.0)\n\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n\u001B[0m\u001B[38;5;2m✔ Download and installation successful\u001B[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/berndheidemann/twitter_disaster_text_classification.git"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-06T12:06:46.904756Z",
     "iopub.execute_input": "2023-02-06T12:06:46.905173Z",
     "iopub.status.idle": "2023-02-06T12:06:47.928938Z",
     "shell.execute_reply.started": "2023-02-06T12:06:46.905126Z",
     "shell.execute_reply": "2023-02-06T12:06:47.927692Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": "fatal: destination path 'twitter_disaster_text_classification' already exists and is not an empty directory.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "path=\"./\"\n",
    "#path=\"/kaggle/working/twitter_disaster_text_classification/\"\"\n",
    "train_csv=path+\"train.csv\"\n",
    "test_csv=path+\"test.csv\"\n",
    "submission_csv=path+\"sample_submission.csv\"\n",
    "\n",
    "df = pd.read_csv(train_csv)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T12:56:29.129862Z",
     "iopub.execute_input": "2023-02-06T12:56:29.130230Z",
     "iopub.status.idle": "2023-02-06T12:56:29.159506Z",
     "shell.execute_reply.started": "2023-02-06T12:56:29.130191Z",
     "shell.execute_reply": "2023-02-06T12:56:29.158467Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "7613"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "# create iterator from tokenized df\n",
    "def df_iterator_content(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield tokenizer(row['text'])\n",
    "\n",
    "vocab = build_vocab_from_iterator(df_iterator_content(df), specials=[\"<unk>\"], min_freq=5)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T12:56:32.813357Z",
     "iopub.execute_input": "2023-02-06T12:56:32.814463Z",
     "iopub.status.idle": "2023-02-06T12:56:35.822767Z",
     "shell.execute_reply.started": "2023-02-06T12:56:32.814414Z",
     "shell.execute_reply": "2023-02-06T12:56:35.821590Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TwitterDisasterDataset(Dataset):\n",
    "    def __init__(self, df, word_count=500, vocab_size=10000, train=True):\n",
    "        self.df = df\n",
    "        self.word_count = word_count\n",
    "        self.vocab_size = vocab_size\n",
    "        self.train=train\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        x= self.df.iloc[idx][\"text\"]\n",
    "        x = vocab(tokenizer(x))\n",
    "        if self.train:\n",
    "            y= self.df.iloc[idx][\"target\"]\n",
    "            y = int(y)\n",
    "        if len(x) > self.word_count:\n",
    "            x=x[:self.word_count]\n",
    "        else:\n",
    "            x.extend([0]*(self.word_count-len(x)))\n",
    "        x = torch.tensor(x)\n",
    "        if self.train:\n",
    "            return x.to(device), torch.tensor(y).to(device)\n",
    "        else:\n",
    "            return x.to(device)\n",
    "\n",
    "twitter_dataset = TwitterDisasterDataset(df, word_count=30, vocab_size=vocab_size)\n",
    "x,y=twitter_dataset[0]\n",
    "print(x.shape)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T12:06:51.061876Z",
     "iopub.execute_input": "2023-02-06T12:06:51.062528Z",
     "iopub.status.idle": "2023-02-06T12:06:51.074862Z",
     "shell.execute_reply.started": "2023-02-06T12:06:51.062489Z",
     "shell.execute_reply": "2023-02-06T12:06:51.073930Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30])\n",
      "tensor(1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, out_size, word_count=50, dropout=0.2, num_layers=2):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout, num_layers=num_layers)\n",
    "        self.dropout=nn.Dropout(p=dropout)\n",
    "        # The linear layer that maps from hidden state space to output space\n",
    "        self.hidden2output = nn.Linear(hidden_dim*word_count, out_size)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        #print(\"xb shape\", xb.shape)\n",
    "        embeds = self.word_embeddings(xb)\n",
    "        #print(\"embeds shape\", embeds.shape)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out=self.dropout(lstm_out)\n",
    "        #print(\"lstm_out shape\", lstm_out.shape)\n",
    "        # lstm_out_view = lstm_out[:, -1, :]   # works but looses information\n",
    "        lstm_out_view = lstm_out.reshape(xb.shape[0], -1   )\n",
    "        #print(\"lstm_out_view shape\", lstm_out_view.shape)\n",
    "        hidden_space = self.hidden2output(lstm_out_view)\n",
    "        #print(\"hidden_space shape\", hidden_space.shape)\n",
    "        output = F.log_softmax(hidden_space, dim=1)\n",
    "        #print(\"output shape\", output.shape)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T12:06:51.076365Z",
     "iopub.execute_input": "2023-02-06T12:06:51.076947Z",
     "iopub.status.idle": "2023-02-06T12:06:51.088237Z",
     "shell.execute_reply.started": "2023-02-06T12:06:51.076911Z",
     "shell.execute_reply": "2023-02-06T12:06:51.087143Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    with torch.no_grad():\n",
    "        for idx, (text, label) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "            y_pred.extend(predicted_label.argmax(1).cpu().numpy())\n",
    "    return f1_score(y_true, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T12:18:39.995657Z",
     "iopub.execute_input": "2023-02-06T12:18:39.996026Z",
     "iopub.status.idle": "2023-02-06T12:18:40.002292Z",
     "shell.execute_reply.started": "2023-02-06T12:18:39.995993Z",
     "shell.execute_reply": "2023-02-06T12:18:40.001201Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameter\n",
    "embed_dim = 128\n",
    "num_class = 2\n",
    "hidden_dim = 64\n",
    "word_count = 30\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 0.01  # learning rate\n",
    "scheduler_patience=4\n",
    "scheduler_factor=0.2\n",
    "weight_decay=1e-4\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "dropout=0.7\n",
    "num_layers=5\n",
    "\n",
    "# check if model works\n",
    "model= MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout, num_layers=num_layers).to(device)\n",
    "dataset = TwitterDisasterDataset(df, word_count=word_count, vocab_size=vocab_size)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "xb, yb = next(iter(loader))\n",
    "print(\"yb\", yb)\n",
    "print(\"xb\", xb.shape)\n",
    "model(xb)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:03:18.936639Z",
     "iopub.execute_input": "2023-02-06T13:03:18.937048Z",
     "iopub.status.idle": "2023-02-06T13:03:18.966718Z",
     "shell.execute_reply.started": "2023-02-06T13:03:18.937012Z",
     "shell.execute_reply": "2023-02-06T13:03:18.965710Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yb tensor([1, 0, 0, 1, 0])\n",
      "xb torch.Size([5, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.7228, -0.6644],\n        [-0.7330, -0.6548],\n        [-0.7458, -0.6432],\n        [-0.6763, -0.7103],\n        [-0.7099, -0.6766]], grad_fn=<LogSoftmaxBackward0>)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001}\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter search\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {\n",
    "    \"embed_dim\": [64, 128],\n",
    "    \"hidden_dim\": [64, 128],\n",
    "    \"dropout\": [0.4, 0.7],\n",
    "    \"num_layers\": [2, 5],\n",
    "    \"weight_decay\": [1e-4, 1e-6],\n",
    "    \"LR\": [0.01, 0.001],\n",
    "    \"BATCH_SIZE\": [64, 256]\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "\n",
    "print(next(iter(param_grid)))\n",
    "print(len(param_grid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6629370629370629\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 38\u001B[0m\n\u001B[0;32m     36\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, (text, label) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[1;32m---> 38\u001B[0m     predicted_label \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_func(predicted_label, label)\n\u001B[0;32m     40\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[6], line 27\u001B[0m, in \u001B[0;36mMyLSTM.forward\u001B[1;34m(self, xb)\u001B[0m\n\u001B[0;32m     25\u001B[0m embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mword_embeddings(xb)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m#print(\"embeds shape\", embeds.shape)\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m lstm_out, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m lstm_out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(lstm_out)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m#print(\"lstm_out shape\", lstm_out.shape)\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# lstm_out_view = lstm_out[:, -1, :]   # works but looses information\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3_neu\\envs\\torch_etc\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    772\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[0;32m    773\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 774\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    775\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    776\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    777\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[0;32m    778\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EPOCHS=4\n",
    "\n",
    "# set all random seeds\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "(gridsearch_portion_idx, test_idx) = next(iter(k_fold.split(df[\"text\"], df[\"target\"])))\n",
    "grid_test_df=df.iloc[test_idx]\n",
    "gridsearch_df=df.iloc[gridsearch_portion_idx]\n",
    "test_dataset=TwitterDisasterDataset(grid_test_df, word_count=word_count, vocab_size=vocab_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "k_fold_iter=iter(k_fold.split(gridsearch_df[\"text\"], gridsearch_df[\"target\"]))\n",
    "\n",
    "i=0\n",
    "best_params_val=0\n",
    "best_params=None\n",
    "for params in param_grid:\n",
    "    i+=1\n",
    "    (base_idx, split_portion_idx)=next(k_fold_iter)\n",
    "    base_df = df.iloc[base_idx]\n",
    "    split_portion_df = df.iloc[split_portion_idx]\n",
    "    train_dataset = TwitterDisasterDataset(split_portion_df, word_count=word_count, vocab_size=vocab_size)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    model = MyLSTM(params[\"embed_dim\"], params[\"hidden_dim\"], vocab_size, num_class, word_count=word_count, dropout=params[\"dropout\"], num_layers=params[\"num_layers\"]).to(device)\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"LR\"], weight_decay=params[\"weight_decay\"])\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for idx, (text, label) in enumerate(train_dataloader):\n",
    "            predicted_label = model(text)\n",
    "            loss = loss_func(predicted_label, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    test_f1 = evaluate(model, test_dataloader)\n",
    "    print(f\"{i} / {len(param_grid)} params {params} Test f1 {test_f1}\")\n",
    "    with open(\"results.txt\", \"a\") as f:\n",
    "        f.write(f\"{i}: params {params} test f1 {test_f1} \\n\")\n",
    "    if test_f1 > best_params_val:\n",
    "        best_params_val = test_f1\n",
    "        best_params = params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "6851\n",
      "762\n",
      "Fold 1\n",
      "6851\n",
      "762\n",
      "Fold 2\n",
      "6851\n",
      "762\n",
      "Fold 3\n",
      "6852\n",
      "761\n",
      "Fold 4\n",
      "6852\n",
      "761\n",
      "Fold 5\n",
      "6852\n",
      "761\n",
      "Fold 6\n",
      "6852\n",
      "761\n",
      "Fold 7\n",
      "6852\n",
      "761\n",
      "Fold 8\n",
      "6852\n",
      "761\n",
      "Fold 9\n",
      "6852\n",
      "761\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# create train and valid dataset\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n",
    "\n",
    "# import torch DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout).to(device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=weight_decay)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_step_size, gamma=lr_gamma)   # every 10 epochs, LR is multiplied by 0.7\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=scheduler_factor, patience=scheduler_patience)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:03:19.418399Z",
     "iopub.execute_input": "2023-02-06T13:03:19.419119Z",
     "iopub.status.idle": "2023-02-06T13:03:19.435078Z",
     "shell.execute_reply.started": "2023-02-06T13:03:19.419075Z",
     "shell.execute_reply": "2023-02-06T13:03:19.434025Z"
    },
    "trusted": true
   },
   "execution_count": 90,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "total_accu = None\n",
    "train_accus=[]\n",
    "valid_accus=[]\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    for idx, (text, label) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text)\n",
    "        loss = loss_func(predicted_label, label)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "    accu_train = evaluate(model, train_dataloader)\n",
    "    accu_valid = evaluate(model, valid_dataloader)\n",
    "    train_accus.append(accu_train)\n",
    "    valid_accus.append(accu_valid)\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | train f1 {:8.3f} | valid f1 {:8.3f} | lr: {:1.5f}'.format(\n",
    "        epoch,\n",
    "        time.time() - epoch_start_time,\n",
    "        accu_train,\n",
    "        accu_valid,\n",
    "        #  scheduler.get_last_lr()[0]))\n",
    "        optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    scheduler.step(accu_valid) # learning rate scheduler after each epoch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_accus, label='train_accu')\n",
    "plt.plot(valid_accus, label='valid_accu')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:03:19.859935Z",
     "iopub.execute_input": "2023-02-06T13:03:19.860315Z",
     "iopub.status.idle": "2023-02-06T13:04:32.106218Z",
     "shell.execute_reply.started": "2023-02-06T13:03:19.860273Z",
     "shell.execute_reply": "2023-02-06T13:04:32.105175Z"
    },
    "trusted": true
   },
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "text": "-----------------------------------------------------------\n| end of epoch   1 | time:  7.59s | train f1    0.725 | valid f1    0.666 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   2 | time:  7.35s | train f1    0.798 | valid f1    0.721 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   3 | time:  7.13s | train f1    0.841 | valid f1    0.733 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   4 | time:  7.18s | train f1    0.842 | valid f1    0.716 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   5 | time:  7.04s | train f1    0.869 | valid f1    0.713 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   6 | time:  7.53s | train f1    0.876 | valid f1    0.703 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   7 | time:  7.11s | train f1    0.920 | valid f1    0.726 | lr: 0.00200\n-----------------------------------------------------------\n| end of epoch   8 | time:  6.98s | train f1    0.937 | valid f1    0.726 | lr: 0.00200\n-----------------------------------------------------------\n| end of epoch   9 | time:  7.13s | train f1    0.946 | valid f1    0.725 | lr: 0.00200\n-----------------------------------------------------------\n| end of epoch  10 | time:  7.01s | train f1    0.956 | valid f1    0.725 | lr: 0.00200\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_test = pd.read_csv(test_csv)\n",
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:05:26.733552Z",
     "iopub.execute_input": "2023-02-06T13:05:26.733904Z",
     "iopub.status.idle": "2023-02-06T13:05:26.758106Z",
     "shell.execute_reply.started": "2023-02-06T13:05:26.733874Z",
     "shell.execute_reply": "2023-02-06T13:05:26.757149Z"
    },
    "trusted": true
   },
   "execution_count": 93,
   "outputs": [
    {
     "execution_count": 93,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_dataset = TwitterDisasterDataset(df_test, word_count=word_count, vocab_size=vocab_size, train=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "predictions=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (text) in enumerate(test_dataloader):\n",
    "        predicted_label = model(text)\n",
    "        predictions.append(predicted_label.argmax(1).cpu().numpy())\n",
    "        \n",
    "\n",
    "predictions=np.concatenate(predictions)\n",
    "print(predictions.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:05:27.904696Z",
     "iopub.execute_input": "2023-02-06T13:05:27.905159Z",
     "iopub.status.idle": "2023-02-06T13:05:29.506107Z",
     "shell.execute_reply.started": "2023-02-06T13:05:27.905117Z",
     "shell.execute_reply": "2023-02-06T13:05:29.505094Z"
    },
    "trusted": true
   },
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "text": "(3263,)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(predictions)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-06T13:05:42.913116Z",
     "iopub.execute_input": "2023-02-06T13:05:42.914087Z",
     "iopub.status.idle": "2023-02-06T13:05:42.920836Z",
     "shell.execute_reply.started": "2023-02-06T13:05:42.914046Z",
     "shell.execute_reply": "2023-02-06T13:05:42.919864Z"
    },
    "trusted": true
   },
   "execution_count": 97,
   "outputs": [
    {
     "execution_count": 97,
     "output_type": "execute_result",
     "data": {
      "text/plain": "3263"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_submission = pd.read_csv(submission_csv)\n",
    "df_submission.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:05:58.407585Z",
     "iopub.execute_input": "2023-02-06T13:05:58.407945Z",
     "iopub.status.idle": "2023-02-06T13:05:58.420647Z",
     "shell.execute_reply.started": "2023-02-06T13:05:58.407914Z",
     "shell.execute_reply": "2023-02-06T13:05:58.419567Z"
    },
    "trusted": true
   },
   "execution_count": 98,
   "outputs": [
    {
     "execution_count": 98,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_submission[\"target\"] = predictions\n",
    "df_submission.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:05:59.444100Z",
     "iopub.execute_input": "2023-02-06T13:05:59.444472Z",
     "iopub.status.idle": "2023-02-06T13:05:59.455787Z",
     "shell.execute_reply.started": "2023-02-06T13:05:59.444440Z",
     "shell.execute_reply": "2023-02-06T13:05:59.454614Z"
    },
    "trusted": true
   },
   "execution_count": 99,
   "outputs": [
    {
     "execution_count": 99,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       1\n4  11       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_submission.to_csv(\"submission.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:06:10.588867Z",
     "iopub.execute_input": "2023-02-06T13:06:10.589614Z",
     "iopub.status.idle": "2023-02-06T13:06:10.609528Z",
     "shell.execute_reply.started": "2023-02-06T13:06:10.589576Z",
     "shell.execute_reply": "2023-02-06T13:06:10.608364Z"
    },
    "trusted": true
   },
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_submission.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-06T13:06:20.954357Z",
     "iopub.execute_input": "2023-02-06T13:06:20.955050Z",
     "iopub.status.idle": "2023-02-06T13:06:20.982140Z",
     "shell.execute_reply.started": "2023-02-06T13:06:20.955006Z",
     "shell.execute_reply": "2023-02-06T13:06:20.981213Z"
    },
    "trusted": true
   },
   "execution_count": 101,
   "outputs": [
    {
     "execution_count": 101,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 id       target\ncount   3263.000000  3263.000000\nmean    5427.152927     0.377567\nstd     3146.427221     0.484853\nmin        0.000000     0.000000\n25%     2683.000000     0.000000\n50%     5500.000000     0.000000\n75%     8176.000000     1.000000\nmax    10875.000000     1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3263.000000</td>\n      <td>3263.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5427.152927</td>\n      <td>0.377567</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3146.427221</td>\n      <td>0.484853</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2683.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5500.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8176.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10875.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
