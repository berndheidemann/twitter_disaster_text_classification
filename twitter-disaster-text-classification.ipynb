{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://www.kaggle.com/competitions/nlp-getting-started\n\n!python -m spacy download en_core_web_sm","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:55:16.191298Z","iopub.execute_input":"2023-02-06T13:55:16.192071Z","iopub.status.idle":"2023-02-06T13:55:40.772827Z","shell.execute_reply.started":"2023-02-06T13:55:16.191631Z","shell.execute_reply":"2023-02-06T13:55:40.771684Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.3.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.3.0) (3.3.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.9)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.8)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.5)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (59.8.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (23.0)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.3.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.14)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/berndheidemann/twitter_disaster_text_classification.git","metadata":{"execution":{"iopub.status.busy":"2023-02-06T13:55:40.775306Z","iopub.execute_input":"2023-02-06T13:55:40.775675Z","iopub.status.idle":"2023-02-06T13:55:42.682296Z","shell.execute_reply.started":"2023-02-06T13:55:40.775635Z","shell.execute_reply":"2023-02-06T13:55:42.681188Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'twitter_disaster_text_classification'...\nremote: Enumerating objects: 22, done.\u001b[K\nremote: Counting objects: 100% (22/22), done.\u001b[K\nremote: Compressing objects: 100% (16/16), done.\u001b[K\nremote: Total 22 (delta 7), reused 20 (delta 6), pack-reused 0\u001b[K\nUnpacking objects: 100% (22/22), 621.20 KiB | 2.60 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n#path=\"./\"\npath=\"/kaggle/working/twitter_disaster_text_classification/\"\ntrain_csv=path+\"train.csv\"\ntest_csv=path+\"test.csv\"\nsubmission_csv=path+\"sample_submission.csv\"\n\ndf = pd.read_csv(train_csv)\ndf.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:55:52.410842Z","iopub.execute_input":"2023-02-06T13:55:52.411221Z","iopub.status.idle":"2023-02-06T13:55:52.456099Z","shell.execute_reply.started":"2023-02-06T13:55:52.411185Z","shell.execute_reply":"2023-02-06T13:55:52.455061Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:55:55.228579Z","iopub.execute_input":"2023-02-06T13:55:55.228930Z","iopub.status.idle":"2023-02-06T13:55:55.235722Z","shell.execute_reply.started":"2023-02-06T13:55:55.228901Z","shell.execute_reply":"2023-02-06T13:55:55.234701Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"7613"},"metadata":{}}]},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\ntokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n\n# create iterator from tokenized df\ndef df_iterator_content(df):\n    for _, row in df.iterrows():\n        yield tokenizer(row['text'])\n\nvocab = build_vocab_from_iterator(df_iterator_content(df), specials=[\"<unk>\"], min_freq=5)\nvocab.set_default_index(vocab[\"<unk>\"])\nvocab_size = len(vocab)\nprint(vocab_size)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:55:55.580883Z","iopub.execute_input":"2023-02-06T13:55:55.581663Z","iopub.status.idle":"2023-02-06T13:56:03.707518Z","shell.execute_reply.started":"2023-02-06T13:55:55.581622Z","shell.execute_reply":"2023-02-06T13:56:03.706427Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"3240\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass TwitterDisasterDataset(Dataset):\n    def __init__(self, df, word_count=500, vocab_size=10000, train=True):\n        self.df = df\n        self.word_count = word_count\n        self.vocab_size = vocab_size\n        self.train=train\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        x= self.df.iloc[idx][\"text\"]\n        x = vocab(tokenizer(x))\n        if self.train:\n            y= self.df.iloc[idx][\"target\"]\n            y = int(y)\n        if len(x) > self.word_count:\n            x=x[:self.word_count]\n        else:\n            x.extend([0]*(self.word_count-len(x)))\n        x = torch.tensor(x)\n        if self.train:\n            return x.to(device), torch.tensor(y).to(device)\n        else:\n            return x.to(device)\n\ntwitter_dataset = TwitterDisasterDataset(df, word_count=30, vocab_size=vocab_size)\nx,y=twitter_dataset[0]\nprint(x.shape)\nprint(y)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:56:03.709617Z","iopub.execute_input":"2023-02-06T13:56:03.710540Z","iopub.status.idle":"2023-02-06T13:56:11.702982Z","shell.execute_reply.started":"2023-02-06T13:56:03.710495Z","shell.execute_reply":"2023-02-06T13:56:11.701915Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"torch.Size([30])\ntensor(1, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\n\ntorch.manual_seed(1)\n\nclass MyLSTM(nn.Module):\n\n    def __init__(self, embedding_dim, hidden_dim, vocab_size, out_size, word_count=50, dropout=0.2, num_layers=2):\n        super(MyLSTM, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.embedding_dim=embedding_dim\n        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout, num_layers=num_layers)\n        self.dropout=nn.Dropout(p=dropout)\n        # The linear layer that maps from hidden state space to output space\n        self.hidden2output = nn.Linear(hidden_dim*word_count, out_size)\n\n    def forward(self, xb):\n        #print(\"xb shape\", xb.shape)\n        embeds = self.word_embeddings(xb)\n        #print(\"embeds shape\", embeds.shape)\n        lstm_out, _ = self.lstm(embeds)\n        lstm_out=self.dropout(lstm_out)\n        #print(\"lstm_out shape\", lstm_out.shape)\n        # lstm_out_view = lstm_out[:, -1, :]   # works but looses information\n        lstm_out_view = lstm_out.reshape(xb.shape[0], -1   )\n        #print(\"lstm_out_view shape\", lstm_out_view.shape)\n        hidden_space = self.hidden2output(lstm_out_view)\n        #print(\"hidden_space shape\", hidden_space.shape)\n        output = F.log_softmax(hidden_space, dim=1)\n        #print(\"output shape\", output.shape)\n        return output","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:56:11.705005Z","iopub.execute_input":"2023-02-06T13:56:11.705988Z","iopub.status.idle":"2023-02-06T13:56:11.715602Z","shell.execute_reply.started":"2023-02-06T13:56:11.705949Z","shell.execute_reply":"2023-02-06T13:56:11.714619Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef evaluate(model, dataloader):\n    model.eval()\n    y_true=[]\n    y_pred=[]\n    with torch.no_grad():\n        for idx, (text, label) in enumerate(dataloader):\n            predicted_label = model(text)\n            y_true.extend(label.cpu().numpy())\n            y_pred.extend(predicted_label.argmax(1).cpu().numpy())\n    return f1_score(y_true, y_pred)\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:56:11.719584Z","iopub.execute_input":"2023-02-06T13:56:11.719866Z","iopub.status.idle":"2023-02-06T13:56:11.785984Z","shell.execute_reply.started":"2023-02-06T13:56:11.719837Z","shell.execute_reply":"2023-02-06T13:56:11.785132Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter\nembed_dim = 128\nnum_class = 2\nhidden_dim = 64\nword_count = 30\nEPOCHS = 10 # epoch\nLR = 0.01  # learning rate\nscheduler_patience=4\nscheduler_factor=0.2\nweight_decay=1e-4\nBATCH_SIZE = 64 # batch size for training\ndropout=0.7\nnum_layers=5\n\n# check if model works\nmodel= MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout, num_layers=num_layers).to(device)\ndataset = TwitterDisasterDataset(df, word_count=word_count, vocab_size=vocab_size)\nloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n\nxb, yb = next(iter(loader))\nprint(\"yb\", yb)\nprint(\"xb\", xb.shape)\nmodel(xb)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:56:11.787246Z","iopub.execute_input":"2023-02-06T13:56:11.787796Z","iopub.status.idle":"2023-02-06T13:56:13.758997Z","shell.execute_reply.started":"2023-02-06T13:56:11.787760Z","shell.execute_reply":"2023-02-06T13:56:13.757992Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"yb tensor([1, 0, 0, 1, 0], device='cuda:0')\nxb torch.Size([5, 30])\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.7036, -0.6828],\n        [-0.7092, -0.6774],\n        [-0.7734, -0.6188],\n        [-0.7146, -0.6721],\n        [-0.7071, -0.6794]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# hyperparameter search\nfrom sklearn.model_selection import ParameterGrid\n\nparam_grid = {\n    \"embed_dim\": [64, 128],\n    \"hidden_dim\": [64, 128],\n    \"dropout\": [0.4, 0.7],\n    \"num_layers\": [2, 5],\n    \"weight_decay\": [1e-4, 1e-6],\n    \"LR\": [0.01, 0.001],\n    \"BATCH_SIZE\": [64, 256]\n}\n\nparam_grid = ParameterGrid(param_grid)\n\nprint(next(iter(param_grid)))\nprint(len(param_grid))","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:56:13.760559Z","iopub.execute_input":"2023-02-06T13:56:13.760903Z","iopub.status.idle":"2023-02-06T13:56:13.782771Z","shell.execute_reply.started":"2023-02-06T13:56:13.760869Z","shell.execute_reply":"2023-02-06T13:56:13.781822Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001}\n128\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport time\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\n\nEPOCHS=10\n\n# set all random seeds\ntorch.manual_seed(1)\nnp.random.seed(1)\n\nk_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n(gridsearch_portion_idx, test_idx) = next(iter(k_fold.split(df[\"text\"], df[\"target\"])))\ngrid_test_df=df.iloc[test_idx]\ngridsearch_df=df.iloc[gridsearch_portion_idx]\ntest_dataset=TwitterDisasterDataset(grid_test_df, word_count=word_count, vocab_size=vocab_size)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\n\nk_fold_iter=iter(k_fold.split(gridsearch_df[\"text\"], gridsearch_df[\"target\"]))\n(base_idx, split_portion_idx)=next(k_fold_iter)\nbase_df = df.iloc[base_idx]\nsplit_portion_df = df.iloc[split_portion_idx]\ntrain_dataset = TwitterDisasterDataset(split_portion_df, word_count=word_count, vocab_size=vocab_size)\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\ni=0\nbest_params_val=0\nbest_params=None\nfor params in param_grid:\n    i+=1\n    \n    model = MyLSTM(params[\"embed_dim\"], params[\"hidden_dim\"], vocab_size, num_class, word_count=word_count, dropout=params[\"dropout\"], num_layers=params[\"num_layers\"]).to(device)\n    loss_func = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"LR\"], weight_decay=params[\"weight_decay\"])\n    for epoch in range(EPOCHS):\n        model.train()\n        for idx, (text, label) in enumerate(train_dataloader):\n            predicted_label = model(text)\n            loss = loss_func(predicted_label, label)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n    test_f1 = evaluate(model, test_dataloader)\n    print(f\"{i} / {len(param_grid)} params {params} Test f1 {test_f1}\")\n    with open(\"results.txt\", \"a\") as f:\n        f.write(f\"{i}: params {params} test f1 {test_f1} \\n\")\n    if test_f1 > best_params_val:\n        best_params_val = test_f1\n        best_params = params","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T14:02:40.575523Z","iopub.execute_input":"2023-02-06T14:02:40.575879Z","iopub.status.idle":"2023-02-06T14:12:39.985097Z","shell.execute_reply.started":"2023-02-06T14:02:40.575849Z","shell.execute_reply":"2023-02-06T14:12:39.984075Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"1 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6502463054187192\n2 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6688311688311689\n3 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6212914485165795\n4 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6559485530546624\n5 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6220839813374804\n6 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6058732612055642\n7 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6695652173913044\n8 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6780104712041884\n9 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6487394957983194\n10 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.668820678513732\n11 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6508379888268156\n12 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6638054363376251\n13 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6184012066365008\n14 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6588235294117646\n15 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6003898635477583\n16 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6440677966101696\n17 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6666666666666667\n18 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6676970633693972\n19 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6553191489361702\n20 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6872964169381108\n21 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6556390977443609\n22 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6657183499288762\n23 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5798045602605864\n24 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6562054208273894\n25 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6074313408723747\n26 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.676829268292683\n27 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5915492957746479\n28 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.686695278969957\n29 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6588235294117647\n30 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.684375\n31 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.4968944099378881\n32 / 128 params {'BATCH_SIZE': 64, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6519174041297935\n33 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6172006745362564\n34 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6499999999999999\n35 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.638235294117647\n36 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.5241090146750524\n37 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6111111111111112\n38 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6210191082802548\n39 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5781818181818181\n40 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.626970227670753\n41 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6134969325153374\n42 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6524216524216524\n43 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5483870967741935\n44 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6380165289256198\n45 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.618705035971223\n46 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6199999999999999\n47 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6648501362397821\n48 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.31077694235588976\n49 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.5983471074380167\n50 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6183574879227053\n51 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.545751633986928\n52 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.5210420841683366\n53 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6184448462929476\n54 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6594427244582043\n55 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5131313131313132\n56 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6557377049180328\n57 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.5869947275922672\n58 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6172413793103448\n59 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6448736998514115\n60 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6324237560192617\n61 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6209150326797385\n62 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6167557932263815\n63 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5827338129496402\n64 / 128 params {'BATCH_SIZE': 64, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6309963099630996\n65 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.7004341534008683\n66 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6644628099173553\n67 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6776406035665296\n68 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6590538336052203\n69 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6565096952908587\n70 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6458658346333853\n71 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5372168284789643\n72 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6515353805073433\n73 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6745213549337261\n74 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6341463414634146\n75 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.651085141903172\n76 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6623586429725363\n77 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6571428571428571\n78 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6515397082658022\n79 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6732919254658385\n80 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.5831702544031312\n81 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6625766871165645\n82 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6726998491704375\n83 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5893536121673003\n84 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.5954692556634306\n85 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.5933333333333333\n86 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6531881804043546\n87 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5689655172413792\n88 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6676783004552354\n89 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6579804560260587\n90 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6485623003194889\n91 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6666666666666667\n92 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6745913818722139\n93 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.654485049833887\n94 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6750392464678178\n95 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6325878594249201\n96 / 128 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6517241379310345\n97 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6442748091603053\n98 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6754772393538913\n99 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6259097525473071\n100 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6360544217687075\n101 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6577896138482024\n102 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6489859594383776\n103 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5753899480069323\n104 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.5919439579684763\n105 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6356073211314476\n106 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6202090592334495\n107 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6354883081155434\n108 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6117216117216117\n109 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6225165562913908\n110 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6296296296296295\n111 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.6298157453936347\n112 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6601307189542484\n113 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6364963503649635\n114 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6312178387650086\n115 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.5270758122743683\n116 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.5372549019607843\n117 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.6080843585237259\n118 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.675595238095238\n119 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.4361233480176211\n120 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.49040511727078884\n121 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.607017543859649\n122 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6721763085399449\n123 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.576991150442478\n124 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6765676567656765\n125 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 0.0001} Test f1 0.558659217877095\n126 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 2, 'weight_decay': 1e-06} Test f1 0.6477541371158393\n127 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 0.0001} Test f1 0.613240418118467\n128 / 128 params {'BATCH_SIZE': 256, 'LR': 0.001, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'num_layers': 5, 'weight_decay': 1e-06} Test f1 0.6392092257001648\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T14:12:42.354492Z","iopub.execute_input":"2023-02-06T14:12:42.357839Z","iopub.status.idle":"2023-02-06T14:12:42.369231Z","shell.execute_reply.started":"2023-02-06T14:12:42.357796Z","shell.execute_reply":"2023-02-06T14:12:42.367391Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'BATCH_SIZE': 256,\n 'LR': 0.01,\n 'dropout': 0.4,\n 'embed_dim': 64,\n 'hidden_dim': 64,\n 'num_layers': 2,\n 'weight_decay': 0.0001}"},"metadata":{}}]},{"cell_type":"code","source":"best_params_val","metadata":{"execution":{"iopub.status.busy":"2023-02-06T14:12:54.403318Z","iopub.execute_input":"2023-02-06T14:12:54.403671Z","iopub.status.idle":"2023-02-06T14:12:54.409636Z","shell.execute_reply.started":"2023-02-06T14:12:54.403642Z","shell.execute_reply":"2023-02-06T14:12:54.408629Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0.7004341534008683"},"metadata":{}}]},{"cell_type":"code","source":"\n# create train and valid dataset\ntrain_dataset, valid_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n\n# import torch DataLoader\nfrom torch.utils.data import DataLoader\n\nmodel = MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout).to(device)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=weight_decay)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_step_size, gamma=lr_gamma)   # every 10 epochs, LR is multiplied by 0.7\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=scheduler_factor, patience=scheduler_patience)\n\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:03:19.418399Z","iopub.execute_input":"2023-02-06T13:03:19.419119Z","iopub.status.idle":"2023-02-06T13:03:19.435078Z","shell.execute_reply.started":"2023-02-06T13:03:19.419075Z","shell.execute_reply":"2023-02-06T13:03:19.434025Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"total_accu = None\ntrain_accus=[]\nvalid_accus=[]\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n\n    model.train()\n    total_acc, total_count = 0, 0\n\n    for idx, (text, label) in enumerate(train_dataloader):\n        optimizer.zero_grad()\n        predicted_label = model(text)\n        loss = loss_func(predicted_label, label)\n        loss.backward()\n        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n\n    accu_train = evaluate(model, train_dataloader)\n    accu_valid = evaluate(model, valid_dataloader)\n    train_accus.append(accu_train)\n    valid_accus.append(accu_valid)\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | train f1 {:8.3f} | valid f1 {:8.3f} | lr: {:1.5f}'.format(\n        epoch,\n        time.time() - epoch_start_time,\n        accu_train,\n        accu_valid,\n        #  scheduler.get_last_lr()[0]))\n        optimizer.param_groups[0]['lr']))\n\n    scheduler.step(accu_valid) # learning rate scheduler after each epoch\n\nimport matplotlib.pyplot as plt\nplt.plot(train_accus, label='train_accu')\nplt.plot(valid_accus, label='valid_accu')\nplt.legend()\nplt.show()","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:03:19.859935Z","iopub.execute_input":"2023-02-06T13:03:19.860315Z","iopub.status.idle":"2023-02-06T13:04:32.106218Z","shell.execute_reply.started":"2023-02-06T13:03:19.860273Z","shell.execute_reply":"2023-02-06T13:04:32.105175Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"-----------------------------------------------------------\n| end of epoch   1 | time:  7.59s | train f1    0.725 | valid f1    0.666 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   2 | time:  7.35s | train f1    0.798 | valid f1    0.721 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   3 | time:  7.13s | train f1    0.841 | valid f1    0.733 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   4 | time:  7.18s | train f1    0.842 | valid f1    0.716 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   5 | time:  7.04s | train f1    0.869 | valid f1    0.713 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   6 | time:  7.53s | train f1    0.876 | valid f1    0.703 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   7 | time:  7.11s | train f1    0.920 | valid f1    0.726 | lr: 0.00200\n-----------------------------------------------------------\n| end of epoch   8 | time:  6.98s | train f1    0.937 | valid f1    0.726 | lr: 0.00200\n-----------------------------------------------------------\n| end of epoch   9 | time:  7.13s | train f1    0.946 | valid f1    0.725 | lr: 0.00200\n-----------------------------------------------------------\n| end of epoch  10 | time:  7.01s | train f1    0.956 | valid f1    0.725 | lr: 0.00200\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt50lEQVR4nO3deXxU1f3/8dcnG9lDEgJkgQCyhC1hCWGriqUqqIgoWuoKKBQ31Far39b+7F6/lv5a/GmhoEBRXHCnLYiiIi1uCQLZZDNACAkhIWQlIdv5/XEHCJjABBLuzOTzfDCPzMy9d+YzQ/KeM+eee64YY1BKKeW5vOwuQCmlVPvSoFdKKQ+nQa+UUh5Og14ppTycBr1SSnk4H7sLaE6XLl1Mr1697C5DKaXcxpYtW4qNMVHNLXPJoO/VqxdpaWl2l6GUUm5DRPa3tEy7bpRSysNp0CullIfToFdKKQ/nkn30zamrqyMvL4+amhq7S/E4/v7+xMXF4evra3cpSql24DZBn5eXR0hICL169UJE7C7HYxhjOHLkCHl5efTu3dvucpRS7cBtum5qamqIjIzUkG9jIkJkZKR+U1LKg7lN0AMa8u1E31elPJvbdN0opZQnqm9oZFdhJel5pZRW1zHv8kva/Dk06JVS6iJpbDTsPVJFel4p6XllpOeVkZVfRk1dIwBdQzox99I+eHm17bdsp4JeRCYBCwFv4AVjzNNnLA8HlgGXADXAbGNMpmPZPqACaADqjTHJbVb9RVRaWsorr7zCfffd16rtrrnmGl555RU6d+7cPoUppVySMYaDpdUnAz09r5SMg2VU1NQD4O/rxZCYMG5NiSepRxiJcZ2Jjwhs85AHJ4JeRLyB54ErgTwgVUTWGGOym6z2c2CbMWaaiCQ41p/YZPkVxpjiNqz7oistLeVvf/vbd4K+oaEBb2/vFrdbu3Zte5emlHIBRRXHm7TUrZ9HqmoB8PUWErqHcn1SDElxnUnsEUbfqGB8vC/OblJnWvQpwB5jTA6AiLwGTAWaBv0g4I8AxpgdItJLRLoZYwrbumCAX/8zi+z88jZ9zEExoTw1ZXCLy5944gm+/fZbhg0bhq+vL8HBwURHR7Nt2zays7O54YYbOHDgADU1NTz00EPMnTsXODVvT2VlJZMnT+Z73/sen332GbGxsbz33nsEBAQ0+3xLly5lyZIl1NbW0rdvX1566SUCAwMpLCxk3rx55OTkALBo0SLGjRvHypUrWbBgASJCYmIiL730EjNnzuS6665j+vTpAAQHB1NZWdmm75tSHVFZdR0ZeWWkHywl/YAV7Pll1sg1L4G+XYO5IqErSXFWSz0hOoROPi03CNubM0EfCxxocjsPGH3GOtuBG4H/ikgKEA/EAYWAAT4QEQP83Riz5IKrtsHTTz9NZmYm27ZtY+PGjVx77bVkZmaeHHu+bNkyIiIiqK6uZtSoUdx0001ERkae9hi7d+/m1VdfZenSpdxyyy289dZb3H777c0+34033sicOXMAePLJJ3nxxRd58MEHmT9/PpdffjnvvPMODQ0NVFZWkpWVxe9//3s2b95Mly5dKCkpad83Q6kO5FhtPVn55Ww/YHW9pOeVsbe46uTy+MhARvaKYLYj1AfHhBLUybV2fzpTTXMdRmeeUfxpYKGIbAMygK1AvWPZeGNMvoh0BT4UkR3GmE3feRKRucBcgJ49e561oLO1vC+WlJSU0w4wevbZZ3nnnXcAOHDgALt37/5O0Pfu3Zthw4YBMHLkSPbt29fi42dmZvLkk09SWlpKZWUlV199NQAff/wxK1euBMDb25uwsDBWrlzJ9OnT6dKlCwARERFt9TKV6lBq6xvZcaj8tO6XXYUVNDoSr3uoP4lxYUwfGUdiXBhDY8PoHOhnb9FOcCbo84AeTW7HAflNVzDGlAOzAMQalL3XccEYk+/4eVhE3sHqCvpO0Dta+ksAkpOTz/wgcTlBQUEnr2/cuJENGzbw+eefExgYyIQJE5o9AKlTp04nr3t7e1NdXd3i48+cOZN3332XpKQkVqxYwcaNG1tc1xjT7Fh4Hx8fGhsbT65TW1vrzEtTqkOorW9kV2EFWfllZB4sJz2vlG8KKqhtsP5mwgN9SYzrzFWDupEY15nEuDC6hvrbXPX5cSboU4F+ItIbOAjMAG5tuoKIdAaOGWNqgXuATcaYchEJAryMMRWO61cBv2nLF3CxhISEUFFR0eyysrIywsPDCQwMZMeOHXzxxRcX/HwVFRVER0dTV1fHqlWriI2NBWDixIksWrSIhx9+mIaGBqqqqpg4cSLTpk3jkUceITIykpKSEiIiIujVqxdbtmzhlltu4b333qOuru6C61LKHVUdr2fHoXIyD5afDPbdhyuoa7DalMGdfBgSG8qs8b0YGhdGUlxn4sIDPOZgwnMGvTGmXkQeANZjDa9cZozJEpF5juWLgYHAShFpwNpJe7dj827AO443ywd4xRjzftu/jPYXGRnJ+PHjGTJkCAEBAXTr1u3kskmTJrF48WISExMZMGAAY8aMueDn++1vf8vo0aOJj49n6NChJz9kFi5cyNy5c3nxxRfx9vZm0aJFjB07ll/84hdcfvnleHt7M3z4cFasWMGcOXOYOnUqKSkpTJw48bRvIUp5qqNVtWTlW4GelV9OZr7Vp24c/QQRQX4Mjgnlsv59GBwTypDYsHYb1ugqxBjX6yVJTk42Z55h6ptvvmHgwIE2VeT59P1V7sYYQ2H58ZMt9BPBfrD0VJdoTJg/g2LCGBIbymDHz+6h/h7TUm9KRLa0dJySa+0aVkqpZjQ2GnJLjp1soWfll5N18NQ4dRHoHRnEiPhw7hgbz+AYK9gjglx/R+nFoEFvs/vvv5/Nmzefdt9DDz3ErFmzbKpIKXvVNzSyp6jytFZ6dn45lcetgXw+XkK/biF8P6GrFeixYQyMDiXYxYY0uhJ9Z2z2/PPP212CUrapqWtgx6EKMg+eCPQyvjlUQW29NfLF39eLgdGhTBsee7KV3r97sK0HH7kjDXql1EVVUlXLh9mHWJtxiM++LT458iXU34fBMWHcNTb+ZH967y7BeHvwTtKLRYNeKdXuiiqO80H2IdZlHOLznCM0NBp6RAQwc1wvRsaHMzgmzKOGM7oaDXqlVLsoLK9hfdYh1mYU8NXeEhoN9IoM5MeX9eGaodEMjgnVYL9INOiVUm0mv7SadZmHWJdRwJbcoxhjTfD1wBV9mTw0moTuIRruNtCgbycnZorMz89n/vz5vPnmm99ZZ8KECSxYsIDkZLecol8pAA6UHGNdZgFrMw6x7UApAAndQ3jkB/2ZPKQ7/bqF2Fug0qBvbzExMc2GvFLubF9xFWszC1iXcYiMg2UADIkN5bGrBzB5SHf6RAXbXKFqyj2Dft0TcCijbR+z+1CY/HSLix9//HHi4+NPnnjkV7/6FSLCpk2bOHr0KHV1dfzud79j6tSpp223b98+rrvuOjIzM6murmbWrFlkZ2czcODAs05qBnDvvfeSmppKdXU106dP59e//jUAqampPPTQQ1RVVdGpUyc++ugjAgMDefzxx1m/fj0iwpw5c3jwwQdPzoffpUsX0tLSePTRR886QZpSLdlzuJJ1GQWszTzENwXW+SCSenTmfyYnMHlIND0jA22uULXEPYPeBjNmzODhhx8+GfSrV6/m/fff55FHHiE0NJTi4mLGjBnD9ddf32If5KJFiwgMDCQ9PZ309HRGjBhx1uf8/e9/T0REBA0NDUycOJH09HQSEhL44Q9/yOuvv86oUaMoLy8nICCAJUuWsHfvXrZu3YqPj4/OSa8umDGGXYWVrM0oYF1mAbsKrZPWjIwP58lrBzJpSHfiwjXc3YF7Bv1ZWt7tZfjw4Rw+fJj8/HyKiooIDw8nOjqaRx55hE2bNuHl5cXBgwcpLCyke/fuzT7Gpk2bmD9/PgCJiYkkJiae9TlXr17NkiVLqK+vp6CggOzsbESE6OhoRo0aBUBoaCgAGzZsYN68efj4WP+lOie9Oh/GGLLyy1nn6JbJKa5CBFJ6RfDr6wdz9eDudA9zz6l6OzL3DHqbTJ8+nTfffJNDhw4xY8YMVq1aRVFREVu2bMHX15devXo1Ow99U86OONi7dy8LFiwgNTWV8PBwZs6cSU1NTYtzzzszJ/25alMdkzGG9Lyyk33uuSXH8BIYe0kks7/Xm6sGd6NriIa7O9Ogb4UZM2YwZ84ciouL+fTTT1m9ejVdu3bF19eXTz75hP379591+8suu4xVq1ZxxRVXkJmZSXp6eovrlpeXExQURFhYGIWFhaxbt44JEyaQkJBAfn4+qampjBo1ioqKCgICArjqqqtYvHgxEyZMONl103RO+smTJ/PWW2+19Vui3FRjo2HrgVLWZRSwLvMQB0ur8fESxvXtwn0TLuHKQd2IDO507gdSbkGDvhUGDx5MRUUFsbGxREdHc9tttzFlyhSSk5MZNmwYCQkJZ93+3nvvZdasWSQmJjJs2DBSUlJaXDcpKYnhw4czePBg+vTpw/jx4wHw8/Pj9ddf58EHH6S6upqAgAA2bNjAPffcw65du0hMTMTX15c5c+bwwAMP8NRTT3H33Xfzhz/8gdGjzzzVr+qIdhVWMHdlGvuOHMPXW7i0XxQP/6AfVw7q5hanxVOtp/PRK0Df344idV8Jd69Ixd/XmycmJ/CDQd0I9fe1uyzVBnQ+eqUU67MOMf/VrcR2DuAfs1PoEaEjZjoKDXoXMHr0aI4fP37afS+99BJDhw61qSLlaV75Mpcn381gaFxnls8cpSfk6GDcKuhbGlni7r788ktbn98Vu+9U2zDGsPCj3fx1w24mDIjib7eNINDPrf7sVRvwsrsAZ/n7+3PkyBENpTZmjOHIkSP4++vwOU/T0Gj4xbuZ/HXDbm4aEcfSO5M15Dsot/lfj4uLIy8vj6KiIrtL8Tj+/v7ExcXZXYZqQzV1Dcx/dSsfZBdy74RL+NnVAzzy27ByjtsEva+vL71797a7DKVcXtmxOuasTCN1fwlPTRnErPH6d9PRuU3QK6XOraCsmpnLUskpruTZGcOZkhRjd0nKBWjQK+Uh9hyu4M4Xv6K8pp5/zEphXN8udpekXIQGvVIeYMv+EmavSMPX24vX5o5hSGyY3SUpF+LUqBsRmSQiO0Vkj4g80czycBF5R0TSReQrERni7LZKqQuzIbuQ2174kvBAX96+d5yGvPqOcwa9iHgDzwOTgUHAj0Rk0Bmr/RzYZoxJBO4EFrZiW6XUeXo9NZcfv7yF/t1CePPecXryD9UsZ1r0KcAeY0yOMaYWeA2YesY6g4CPAIwxO4BeItLNyW2VUq1kjOG5j3fz+FsZjO/bhVfnjKGLzjapWuBM0McCB5rcznPc19R24EYAEUkB4oE4J7dVSrVCQ6PhqTVZLPhgF9OGx/LCnckEddLdbaplzvx2NHeUxZmHpz4NLBSRbUAGsBWod3Jb60lE5gJzAXr27OlEWUp1PDV1Dfxk9TbWZhxi7mV9eGJSAl5eeiCUOjtngj4P6NHkdhyQ33QFY0w5MAtArMPv9jougefatsljLAGWgDVNsXPlK9VxlNfUMecfaXy5t4Qnrx3IPZf2sbsk5Sac6bpJBfqJSG8R8QNmAGuariAinR3LAO4BNjnC/5zbKqXOrbC8hlsWf87XuUdZOGOYhrxqlXO26I0x9SLyALAe8AaWGWOyRGSeY/liYCCwUkQagGzg7rNt2z4vRSnP9G1RJXe++BWlx2pZNnMUl/aLsrsk5Wbc5gxTSnVEW3OPMntFKt5ewvKZKQyN0zHyqnl6himl3NAnOw5z36qv6RraiZWzU4iPDLK7JOWmNOiVckFvpB3gibczGBgdwvKZKUSF6Bh5df406JVyIcYY/rbxW/60fiff69uFxXeMJFjHyKsLpL9BSrmIxkbDb/6VzYrP9nF9UgwLbk7Cz8dtTgKnXJgGvVIu4Hh9Az9ZvZ1/pxdw9/d684trBuqBUKrNaNArZbPymjp+vHILn+cc4efXJDD3skvsLkl5GA16pWx0uLyGu5ansruwgv97SxI3jtBz96q2p0GvlE1yiiq5c9lXlFTV8sJdyUwY0NXukpSH0qBXygbbD5Qya0UqAK/OGUNSj872FqQ8mga9UhfZxp2Hufflr+kS4sfK2aPp3UUPhFLtS4NeqXZW39BIQVkNuSXH2HaglL98uIv+3UJYMXsUXUP87S5PdQAa9Eq1gWO19eSWHGP/kWPkHjlmXS85Ru6RKvKOVlPfeGpOqe/17cKi20cQ4u9rY8WqI9GgV8oJxhiKK2vJLak6LdD3O64XVx4/bf0Qfx/iIwMZHBPG5KHRxEcE0jMykJ4RgcR2DsA6bYNSF4cGvVIOdQ2NHDxafVprfL+jdX6g5BhVtQ0n1xWB7qH+9IwI5PsJUcRHBtEjIpD4iEDiIwPpHOh3lmdS6uLSoFcdSuXxevYfqTrZGs8tOdEyryK/tIaGJl0sfj5e9HSE95g+kcRHWiHeMyKIuPAA/H29bXwlSjlPg155vAMlx/jLh7vYuKuIkqra05aFB/rSMzKIYT3CmZpkda+c6GbpFuKv0xAoj6BBrzxW6bFanvt4Dys/348ITEmK4ZKoYKuVHmmFeajuEFUdgAa98jg1dQ2s/Hwfz328h4rj9dw8Mo5HruxPdFiA3aUpZQsNeuUxGhsN720/yIL1uzhYWs2EAVE8MTmBhO6hdpemlK006JVH+O/uYv647huy8ssZEhvKM9MTGd+3i91lKeUSNOiVW8vOL+fp93ewaVcRsZ0DWDhjGFMSY3QnqlJNaNArt5RfWs2fP9jF21vzCPX35clrB3LH2Hg6+eiQR6XOpEGv3Ep5TR1/++Rblm/eiwHmXtqH+yb0JSxQR88o1RINeuUWausbefmL/fy/j3dz9Fgd04bH8tOr+hMXHmh3aUq5PA165dKMMfwrvYA/rd9JbskxxveN5H8mD2RIbJjdpSnlNjTolcv6IucIf1z7DdvzykjoHsI/ZqdwWb8uOiGYUq3kVNCLyCRgIeANvGCMefqM5WHAy0BPx2MuMMYsdyzbB1QADUC9MSa5zapXHml3YQVPr9vBRzsOEx3mz4Kbk5g2PBZvHUmj1Hk5Z9CLiDfwPHAlkAekisgaY0x2k9XuB7KNMVNEJArYKSKrjDEnJha5whhT3NbFK89SWF7DXzfs4vXUAwT5+fCzSQOYPb63Th6m1AVypkWfAuwxxuQAiMhrwFSgadAbIESs79TBQAlQ38a1Kg9VebyeJZ9+y9L/7KW+sZG7xvXiwe/3IyJIp/pVqi04E/SxwIEmt/OA0Wes8xywBsgHQoAfGmMaHcsM8IGIGODvxpglzT2JiMwF5gL07NnT6Reg3FddQyOvfZXLXzfs5khVLdclRvPY1QOIj9RzqCrVlpwJ+uY6Rs0Zt68GtgHfBy4BPhSR/xhjyoHxxph8EenquH+HMWbTdx7Q+gBYApCcnHzm4ysPYoxhfdYh/vf9newtriKldwQvXjOQYT06212aUh7JmaDPA3o0uR2H1XJvahbwtDHGAHtEZC+QAHxljMkHMMYcFpF3sLqCvhP0qmPYsr+EP6zdwZb9R+nbNZgX7kxm4sCuOpJGqXbkTNCnAv1EpDdwEJgB3HrGOrnAROA/ItINGADkiEgQ4GWMqXBcvwr4TZtVr9xGTlElz7y/k/ezDhEV0ok/3jiUm0fG4ePtZXdpSnm8cwa9MaZeRB4A1mMNr1xmjMkSkXmO5YuB3wIrRCQDq6vncWNMsYj0Ad5xtNZ8gFeMMe+302tRTRhj2FVYSXVdA8YYDGAMgMEYTt5uusxgLWh6+9S61no0vf+MZc0+PoYvc0p45atc/H28+MmV/bnn0t4E+ukhHEpdLGL1triW5ORkk5aWZncZbut4fQOPv5nOu9vO7GGzh7eXcGtKT+ZP7EdUSCe7y1HKI4nIlpaOU9JmlYcpPVbL3Je28NXeEh64oi8j4jsjCI5/iIjjJwji+Ilj+anbIk2vWyvIWR6DMx+zyfXwQD8NeKVspEHvQfYfqWLWilTySqpZOGMYU4fF2l2SUsoFaNB7iC37jzJnZRqNxvDyPaNJ6R1hd0lKKRehQe8B1mUU8PDr2+ge5s/ymaPoExVsd0lKKReiQe/GjDEs/U8Of1y3g+E9OrP0zmQig7UvXCl1Og16N1Xf0Miv/pnFy1/kcu3QaP58S5JO/qWUapYGvRuqPF7Pg698zSc7i/jx5X14/OoEPRm2UqpFGvRu5lBZDbNXpLKzsILfTxvCbaPj7S5JKeXiNOjdyDcF5cxankpFTR0v3JXMFQO62l2SUsoNaNC7iU93FXH/qq8J7uTDG/PGMSgm1O6SlFJuQoPeDbzyZS6/fC+Tfl2DWT5rFNFhAXaXpJRyIxr0Lqyx0fDM+p0s/vRbLu8fxXO3DifE39fuspRSbkaD3kXV1DXw0ze28+/0Am4d3ZPfXD9Yp/RVSp0XDXoXVFJVy5yVaWzZf5T/mZzA3Mv66Ik5lFLnTYPexewtrmLW8q/IL6vh+VtHcG1itN0lKaXcnAa9C0ndV8LclWmICK/OGc3IeJ2YTCl14TToXcSa7fk8uno7seEBLJ85il5dguwuSSnlITTobWaM4W8bv+VP63cyqlc4S+5IJjzIz+6ylFIeRIPeRnUNjfzy3UxeSz3A9UkxPDM9UScmU0q1OQ16m1TU1HHfqq/5z+5iHriiLz+5sr9OTKaUahca9DbIL61m9opU9hyu5JmbErllVA+7S1JKeTAN+oss82AZs1ekUl3bwPJZo7i0X5TdJSmlPJwG/UX08Y5CHnhlK50DfHnj3rEkdNeJyZRS7U+D/iJ56fN9PLUmi0Exobx41yi6hfrbXZJSqoPQoG9njY2GP677hqX/2cvEhK48+6PhBHXSt10pdfE4NUuWiEwSkZ0iskdEnmhmeZiI/FNEtotIlojMcnZbT1Zd28B9q75m6X/2ctfYeJbcmawhr5S66M6ZOiLiDTwPXAnkAakissYYk91ktfuBbGPMFBGJAnaKyCqgwYltPVJx5XHu+Uca2/NK+eV1g5g9vpdOTKaUsoUzzcsUYI8xJgdARF4DpgJNw9oAIWIlWTBQAtQDo53Y1uPsOVzJrBVfUVRxnEW3jWTSkO52l6SU6sCc6bqJBQ40uZ3nuK+p54CBQD6QATxkjGl0clsARGSuiKSJSFpRUZGT5bue3CPHuGnRZ1TXNvDa3LEa8kop2zkT9M31N5gzbl8NbANigGHAcyIS6uS21p3GLDHGJBtjkqOi3HNseWOj4bE3t9PYaHhz3jiG9ehsd0lKKeVU0OcBTQ/djMNquTc1C3jbWPYAe4EEJ7f1GCs/38eXe0v45XWDdPZJpZTLcCboU4F+ItJbRPyAGcCaM9bJBSYCiEg3YACQ4+S2HmFfcRVPv7+DCQOiuDk5zu5ylFLqpHPujDXG1IvIA8B6wBtYZozJEpF5juWLgd8CK0QkA6u75nFjTDFAc9u2z0uxT0Oj4dE3tuPr7cXTNybq6BqllEtxalC3MWYtsPaM+xY3uZ4PXOXstp5m+ea9pO0/yp9vTqJ7mB7xqpRyLU4dMKVa9m1RJX9av5MfDOzKjSOaHVCklFK20qC/ACe6bPx9vfnDtKHaZaOUckl6PP4FeOE/OWzNLWXhjGF01UnKlFIuSlv052l3YQV//nAXVw/uxvVJMXaXo5RSLdKgPw/1DY08+sZ2gvy8+d0N2mWjlHJt2nVzHv6+KYfteWU8d+twokI62V2OUkqdlbboW2nHoXL+umEX1w6N5rpE7bJRSrk+DfpWqHN02YQF+PLbG4bYXY5SSjlFu25aYdHGb8k8WM7i20cSEeRndzlKKeUUbdE7KSu/jGc/2s3UYTE69bBSyq1o0Duhtr6RR99IJzzIj19NGWx3OUop1SradeOE5z7ZwzcF5Sy9M5lw7bJRSrkZbdGfQ+bBMp7/ZA83jojlykHd7C5HKaVaTYP+LI7XN/DT1dvpEuzHU9dpl41Syj1p181ZPPvRbnYWVrB85ijCAn3tLkcppc6LtuhbsP1AKYs2fsstyXFckdDV7nKUUuq8adA3o6augZ++sZ1uof48ed0gu8tRSqkLol03zfjLhl3sOVzJytkphPprl41Syr1pi/4MW/YfZemmHH6U0pPL+kfZXY5SSl0wDfomauoaeOyN7USHBfCLawfaXY5SSrUJ7bppYsH6neQUV7HqntEEd9K3RinlGbRF75C6r4QXN+/ljjHxjO/bxe5ylFKqzWjQA8dq63nsje3EhQfwxOQEu8tRSqk2pf0TwDPv72TfkWO8NncMQdplo5TyMB2+Rf9FzhFWfLaPmeN6MaZPpN3lKKVUm3Mq6EVkkojsFJE9IvJEM8sfE5FtjkumiDSISIRj2T4RyXAsS2vrF3Ahqo7X89ib2+kVGcjPJg2wuxyllGoX5+ynEBFv4HngSiAPSBWRNcaY7BPrGGP+BPzJsf4U4BFjTEmTh7nCGFPcppW3gafX7SDvaDWrfzyWQD/tslFKeSZnWvQpwB5jTI4xphZ4DZh6lvV/BLzaFsW1p817innpi/3cPb43o3pF2F2OUkq1G2eCPhY40OR2nuO+7xCRQGAS8FaTuw3wgYhsEZG5LT2JiMwVkTQRSSsqKnKirPNXUVPHz95Mp0+XIB69WrtslFKezZmgl2buMy2sOwXYfEa3zXhjzAhgMnC/iFzW3IbGmCXGmGRjTHJUVPtOPfCHtTsoKKtmwS1J+Pt6t+tzKaWU3ZwJ+jygR5PbcUB+C+vO4IxuG2NMvuPnYeAdrK4g22zaVcSrX+Uy57I+jOgZbmcpSil1UTgT9KlAPxHpLSJ+WGG+5syVRCQMuBx4r8l9QSIScuI6cBWQ2RaFn4+y6joefyudvl2DeeQH/e0qQymlLqpzDjUxxtSLyAPAesAbWGaMyRKReY7lix2rTgM+MMZUNdm8G/COiJx4rleMMe+35Qtojd/9K5vDFcd5+/aR2mWjlOownBpTaIxZC6w9477FZ9xeAaw4474cIOmCKmwjH+8o5I0tedx/xSUk9ehsdzlKKXXRdIgjY8uO1fHEWxkkdA9h/sR+dpejlFIXVYc4SujX/8yipKqWZTNH0clHu2yUUh2Lx7foP8g6xNtbD3L/FX0ZEhtmdzlKKXXReXTQH62q5efvZDIoOpT7r+hrdzlKKWULjw76p9ZkUVZdy4Kbk/Dz8eiX+l0NdVB6AExLx7YppToKj+2jX5dRwJrt+fz0yv4Migm1u5z2d7wS8lIh9wvI/Qzy0qDuGET0gUFTYdANEJ0E0tyBzkopT+aRQX+k8jhPvpvJ0Ngw5k24xO5y2kflYUeof25dCtLBNIB4QbchMPwOCO8Fuz+Azc/Cf/9i3T4R+jHDNfSV6iA8Muj/z3tZVNTUs+DmJHy9PaDLxhgoyTnVWs/9Ao7ssZb5+ENsMlz6E+g5BuJSwL/JN5ix90HVEdjxL8h+Dz5/HjYvhM7xVugPvgFiRmjoK+XBPC7o/5Wez78zCvjZpAEM6B5idznnp6EeCjNPtdZzv4DKQmtZQDj0HAsj7rR+Rg8DH7+zP15QJIy8y7ocK4Ed/4bsd+GLv8Fnz0JYTxh0PQyeBrEjNfSV8jBiXHBnXXJysklLa/3JqIoqjnPVXz6lZ2QQb80bi4+7tOZrj8HBNCvQ939m9bXXVlrLwnpC/Firtd5zHHTpD15t9LqOlcDOtVZL/9tPoLEOwnqc6t6JS9bQ90RVRyD9Nag+ysnJaUWs6yd+nnYfTq7X0n2cvrzp75SI1d141su51mmLx/ACL2/w8mlyaXrb17rtwn8PIrLFGJPc3DKPadEbY3jy3Qyqahv4882Jrh3yVUfggCPUc7+Agm3QWA8IdBsMSTOs1nrPMRAW1351BEbA8NutS/VR2LkOst6FL/8Onz8HoXFWS3/QDRA3qu0+YJQ9ju6zuu6+fgnqq61wM4aWZx1X3yFn+zBo5W1v3+8u9+8Mk/7Q5mV7TNCXV9ezr/gYj17Vn75dXajLxhgo3Q/7m3TDFO+0lnn7WV0l4+Zbwd5jlNU1Y4eAcBh2q3WpLrVCP/s9SH3B6uIJjYWB11t9+nEpGvruJH+b1UWX9Y4VVIk/hHEPQteE09c78e3+RPg3/RC44Ps4+3qmsZlLS/e39ToGGhuswQyN9Y6L43pD3em3T7uceZ8Tt+trzr48oHOb/tef4FFdN8frG/Dx8sLby+avV0U7IefTU33sFQXW/Z3CoOdoR2t9rDXyxdff3lrPpaYMdr5v9env2QANtRASfSr0e4zR0HdFxkDOJ9aO95yN4BcCybNgzL0QGmN3daodnK3rxqOC3iWkr4a351jXQ2NPdcHEj4Ooge4dijXlsOt9q6W/+0NoOA7B3U917/QcY30VVfZpqLc+lDf/FQ5lWP8/Y+61Qt5fpwDxZBr0F8ueDfDKD61wn/o8dO7p0jtvLsjxCti13uoO2LPB+koa3A0GTrFCP36chv7FVFsFW1fB5/8PSnOtnfbj5kPiLeDTye7q1EWgQX8xHNwCK6ZYR6LO+nfHaj2dCP0TLf36agjqaoX+4BsgfryGfnupKoavlsJXS6C6BHqMhvEPQ/9J7v3tUbWaBn17K94Dy64Cv2C4+wMI6W53RfY5XmkdjZv9Luz6wAp9nwBrZ69/WCsvna2Dv7x97X5VrqdkrzWCZuvL1ns84FoYP9/qPlMdUocYXmmb8gJ4aRogcMc7HTvkAToFw5AbrUttlRX6eWlQU2rt2K0pg8pD1sijE7dN49kf0y/4PD4kHB8UnULB24N+zfO3WlNaZL9rjaBJmmGNoIkaYHdlyoV50F+ADWrKYNV0OHYEZv4LIj10Xp3z5RdkHW07eFrL6xhjHRx2IvRbvJSeul5RAEU7Wv9BERpjjXSKGW5N+9Cln3t0KRkD335sjaDZ+6n14TXuQRh9L4RG212dcgMa9OerrgZevdUaSnnbaogdYXdF7kkEOoVYl/M5OMzZD4rqUji619ph+dUSa1u/YGtGz5PhP9zax+IqO9Ab6q2d3ZsXQmGGNaz1yt/AyJkdax+QumAa9OejsQHevgf2/xduehEu+b7dFXVcrf2gaGyA4t2Q/7XVDXLwa2tnZsNxa7l/2KkWf8xw6wM8NPbihn9tlXX06ufPQ1kudBlgjeIaerOOoFHnRYO+tYyBf/8UvvknXP1HGDrd7opUa3h5W0eEdk2wjgIG6+jHw9lW8J8I/8+edUxLgTWC6ESLP9bxARDcte1rqyyyvm2kLrWmpOg5Fq55BvpdrSNo1AXRoG+tT/8Xtiy3hrCNvc/ualRb8Pa1unCik6xuEbC65gozTwV//lZrx/KJQ/hD4yBm2Kngjxl+/tNXlOTAZ8/BtlXW8QgJ1zmmxRjdBi9OKQ361kl9ETb+EZJuhR/8yu5qVHvy9bdm74xrMlrteCUUbHe0/B3hv+Nfp5aH924S/CMgOtHqUmrJiW8O2e9ZE1olzYCxD0JU//Z7XapD0qB3VvYaWPuo9TX6+mddZ4edung6BUOv8dblhOqj1qRhJ4I/90vIfMuxUKxhj037/LsPgf2bHSNoNjlG0MyH0fN0BI1qN04FvYhMAhYC3sALxpinz1j+GHBbk8ccCEQZY0rOta1b2PdfeOsea6bJm1foATzqlIBwuOQK63JC5eFT/f35W2HPR7D9VcdCAYxjBM1vHSNoOsA5jZWtznlkrIh4A7uAK4E8IBX4kTEmu4X1pwCPGGO+39ptT3CpI2MPZcDya6wDoWavt+ZwV6o1jIHyfKvVX7DdGsI5ZPq5zwymVCtc6JGxKcAeY0yO48FeA6YCLYX1j4BXz3Nb13J0P7x8kzXe+va3NeTV+RGBsFjrMnCK3dWoDsiZMVuxwIEmt/Mc932HiAQCk4ATnZSt2XauiKSJSFpRUZETZbWzqmJ4+UZrFMQdb0PnHnZXpJRS58WZoG9ur2NL/T1TgM3GmJLWbmuMWWKMSTbGJEdFRTlRVjs6XgmrboayPLh1NXQdaG89Sil1AZzpuskDmjZn44D8Ftadwalum9Zu6xrqa2H1HdZ5XH+4SmcDVEq5PWda9KlAPxHpLSJ+WGG+5syVRCQMuBx4r7XbuozGRnjvfmsCqSkLIeEauytSSqkLds4WvTGmXkQeANZjDZFcZozJEpF5juWLHatOAz4wxlSda9u2fhFt5sNfQsZq+P4vYcSddlejlFJtQk88csLmZ62gT5kLk5/RA6KUUm7lbMMrdaYkgG2vWiE/eBpMelpDXinlUTTod39o9cv3vgym/d09TkShlFKt0LGDPi8NVt8J3QZbI2x0rm+llAfquEFftMsaKx/cFW5/S+cbUUp5rI4Z9OX51lGvXt7W1AbtcRIJpZRyER1vmuLqo9b8NdVHYea/9YTeSimP17GCvq7aOqF38W64/U3rDEFKKeXhOk7QN9Rbc8rnfg7TX4Q+E+yuSCmlLoqOEfTGwL9/Yp32bfIzMOQmuytSSqmLpmPsjP3kD/D1P+DSn8LoH9tdjVJKXVSeH/RfLYVNz8Dw2605bJRSqoPx7KDPehfWPgb9J8N1C3VqA6VUh+S5Qb93E7w9B3qkwPRl4N0xdkcopdSZPDPoC9KtYZQRfeBHr4FfoN0VKaWUbTwv6Ev2wqrp4B+mJ/RWSik8Legrixwn9D5undA7rNnzkCulVIfiOR3Xxyuslnx5Ady1BqIG2F2RUkq5BM9p0Xv7QZf+cPMKawesUkopwJNa9D6d4KaldlehlFIux3Na9EoppZqlQa+UUh5Og14ppTycBr1SSnk4DXqllPJwGvRKKeXhNOiVUsrDadArpZSHE2OM3TV8h4gUAfvPc/MuQHEbluPO9L04nb4fp9P34xRPeC/ijTFRzS1wyaC/ECKSZoxJtrsOV6Dvxen0/Tidvh+nePp7oV03Sinl4TTolVLKw3li0C+xuwAXou/F6fT9OJ2+H6d49HvhcX30SimlTueJLXqllFJNaNArpZSH85igF5FJIrJTRPaIyBN212MnEekhIp+IyDcikiUiD9ldk91ExFtEtorIv+yuxW4i0llE3hSRHY7fkbF212QnEXnE8XeSKSKvioi/3TW1NY8IehHxBp4HJgODgB+JyCB7q7JVPfBTY8xAYAxwfwd/PwAeAr6xuwgXsRB43xiTACTRgd8XEYkF5gPJxpghgDcww96q2p5HBD2QAuwxxuQYY2qB14CpNtdkG2NMgTHma8f1Cqw/5Fh7q7KPiMQB1wIv2F2L3UQkFLgMeBHAGFNrjCm1tSj7+QABIuIDBAL5NtfT5jwl6GOBA01u59GBg60pEekFDAe+tLkUO/0V+BnQaHMdrqAPUAQsd3RlvSAiQXYXZRdjzEFgAZALFABlxpgP7K2q7XlK0Esz93X4caMiEgy8BTxsjCm3ux47iMh1wGFjzBa7a3ERPsAIYJExZjhQBXTYfVoiEo717b83EAMEicjt9lbV9jwl6POAHk1ux+GBX79aQ0R8sUJ+lTHmbbvrsdF44HoR2YfVpfd9EXnZ3pJslQfkGWNOfMN7Eyv4O6ofAHuNMUXGmDrgbWCczTW1OU8J+lSgn4j0FhE/rJ0pa2yuyTYiIlh9sN8YY/6v3fXYyRjzP8aYOGNML6zfi4+NMR7XYnOWMeYQcEBEBjjumghk21iS3XKBMSIS6Pi7mYgH7pz2sbuAtmCMqReRB4D1WHvNlxljsmwuy07jgTuADBHZ5rjv58aYtfaVpFzIg8AqR6MoB5hlcz22McZ8KSJvAl9jjVbbigdOh6BTICillIfzlK4bpZRSLdCgV0opD6dBr5RSHk6DXimlPJwGvVJKeTgNeqWU8nAa9Eop5eH+P0A0uhmshExwAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"df_test = pd.read_csv(test_csv)\ndf_test.head()","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:05:26.733552Z","iopub.execute_input":"2023-02-06T13:05:26.733904Z","iopub.status.idle":"2023-02-06T13:05:26.758106Z","shell.execute_reply.started":"2023-02-06T13:05:26.733874Z","shell.execute_reply":"2023-02-06T13:05:26.757149Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset = TwitterDisasterDataset(df_test, word_count=word_count, vocab_size=vocab_size, train=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n\npredictions=[]\nmodel.eval()\nwith torch.no_grad():\n    for idx, (text) in enumerate(test_dataloader):\n        predicted_label = model(text)\n        predictions.append(predicted_label.argmax(1).cpu().numpy())\n        \n\npredictions=np.concatenate(predictions)\nprint(predictions.shape)","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:05:27.904696Z","iopub.execute_input":"2023-02-06T13:05:27.905159Z","iopub.status.idle":"2023-02-06T13:05:29.506107Z","shell.execute_reply.started":"2023-02-06T13:05:27.905117Z","shell.execute_reply":"2023-02-06T13:05:29.505094Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"(3263,)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T13:05:42.913116Z","iopub.execute_input":"2023-02-06T13:05:42.914087Z","iopub.status.idle":"2023-02-06T13:05:42.920836Z","shell.execute_reply.started":"2023-02-06T13:05:42.914046Z","shell.execute_reply":"2023-02-06T13:05:42.919864Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"3263"},"metadata":{}}]},{"cell_type":"code","source":"df_submission = pd.read_csv(submission_csv)\ndf_submission.head()","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:05:58.407585Z","iopub.execute_input":"2023-02-06T13:05:58.407945Z","iopub.status.idle":"2023-02-06T13:05:58.420647Z","shell.execute_reply.started":"2023-02-06T13:05:58.407914Z","shell.execute_reply":"2023-02-06T13:05:58.419567Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_submission[\"target\"] = predictions\ndf_submission.head()","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:05:59.444100Z","iopub.execute_input":"2023-02-06T13:05:59.444472Z","iopub.status.idle":"2023-02-06T13:05:59.455787Z","shell.execute_reply.started":"2023-02-06T13:05:59.444440Z","shell.execute_reply":"2023-02-06T13:05:59.454614Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       1\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_submission.to_csv(\"submission.csv\", index=False)","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:06:10.588867Z","iopub.execute_input":"2023-02-06T13:06:10.589614Z","iopub.status.idle":"2023-02-06T13:06:10.609528Z","shell.execute_reply.started":"2023-02-06T13:06:10.589576Z","shell.execute_reply":"2023-02-06T13:06:10.608364Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"df_submission.describe()","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-06T13:06:20.954357Z","iopub.execute_input":"2023-02-06T13:06:20.955050Z","iopub.status.idle":"2023-02-06T13:06:20.982140Z","shell.execute_reply.started":"2023-02-06T13:06:20.955006Z","shell.execute_reply":"2023-02-06T13:06:20.981213Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"                 id       target\ncount   3263.000000  3263.000000\nmean    5427.152927     0.377567\nstd     3146.427221     0.484853\nmin        0.000000     0.000000\n25%     2683.000000     0.000000\n50%     5500.000000     0.000000\n75%     8176.000000     1.000000\nmax    10875.000000     1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3263.000000</td>\n      <td>3263.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5427.152927</td>\n      <td>0.377567</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3146.427221</td>\n      <td>0.484853</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2683.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5500.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8176.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10875.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}