{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.model_selection import StratifiedKFold\nimport time\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-02-13T13:30:26.304536Z","iopub.execute_input":"2023-02-13T13:30:26.305197Z","iopub.status.idle":"2023-02-13T13:30:28.760300Z","shell.execute_reply.started":"2023-02-13T13:30:26.305112Z","shell.execute_reply":"2023-02-13T13:30:28.759010Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/competitions/nlp-getting-started\n\n!python -m spacy download en_core_web_sm","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:30:28.766372Z","iopub.execute_input":"2023-02-13T13:30:28.767057Z","iopub.status.idle":"2023-02-13T13:31:01.330271Z","shell.execute_reply.started":"2023-02-13T13:30:28.767018Z","shell.execute_reply":"2023-02-13T13:31:01.329110Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.3.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.3.0) (3.3.2)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.5)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.9)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (23.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (59.8.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.9)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.3.0)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.1)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.8)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.4)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.12.7)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/berndheidemann/twitter_disaster_text_classification.git","metadata":{"execution":{"iopub.status.busy":"2023-02-13T13:31:01.333343Z","iopub.execute_input":"2023-02-13T13:31:01.334097Z","iopub.status.idle":"2023-02-13T13:31:04.781869Z","shell.execute_reply.started":"2023-02-13T13:31:01.334037Z","shell.execute_reply":"2023-02-13T13:31:04.780611Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'twitter_disaster_text_classification'...\nremote: Enumerating objects: 39, done.\u001b[K\nremote: Counting objects: 100% (39/39), done.\u001b[K\nremote: Compressing objects: 100% (30/30), done.\u001b[K\nremote: Total 39 (delta 16), reused 25 (delta 8), pack-reused 0\u001b[K\nUnpacking objects: 100% (39/39), 686.20 KiB | 817.00 KiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#path=\"./\"\npath=\"/kaggle/working/twitter_disaster_text_classification/\"\ntrain_csv=path+\"train.csv\"\ntest_csv=path+\"test.csv\"\nsubmission_csv=path+\"sample_submission.csv\"\n\ndf = pd.read_csv(train_csv)\ndf.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:04.784228Z","iopub.execute_input":"2023-02-13T13:31:04.784682Z","iopub.status.idle":"2023-02-13T13:31:04.835844Z","shell.execute_reply.started":"2023-02-13T13:31:04.784627Z","shell.execute_reply":"2023-02-13T13:31:04.834796Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"keyword\"].fillna(\"None\", inplace=True)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:04.838806Z","iopub.execute_input":"2023-02-13T13:31:04.839211Z","iopub.status.idle":"2023-02-13T13:31:04.848722Z","shell.execute_reply.started":"2023-02-13T13:31:04.839164Z","shell.execute_reply":"2023-02-13T13:31:04.846525Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df[df.text==\"The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'\"]","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:04.850052Z","iopub.execute_input":"2023-02-13T13:31:04.850424Z","iopub.status.idle":"2023-02-13T13:31:04.866488Z","shell.execute_reply.started":"2023-02-13T13:31:04.850395Z","shell.execute_reply":"2023-02-13T13:31:04.865593Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        id   keyword location  \\\n4284  6087  hellfire      NaN   \n4286  6090  hellfire   Riyadh   \n4292  6097  hellfire      NaN   \n4304  6111  hellfire      NaN   \n4309  6118  hellfire      NaN   \n4318  6132  hellfire      NaN   \n\n                                                   text  target  \n4284  The Prophet (peace be upon him) said 'Save you...       0  \n4286  The Prophet (peace be upon him) said 'Save you...       0  \n4292  The Prophet (peace be upon him) said 'Save you...       1  \n4304  The Prophet (peace be upon him) said 'Save you...       0  \n4309  The Prophet (peace be upon him) said 'Save you...       0  \n4318  The Prophet (peace be upon him) said 'Save you...       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4284</th>\n      <td>6087</td>\n      <td>hellfire</td>\n      <td>NaN</td>\n      <td>The Prophet (peace be upon him) said 'Save you...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4286</th>\n      <td>6090</td>\n      <td>hellfire</td>\n      <td>Riyadh</td>\n      <td>The Prophet (peace be upon him) said 'Save you...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4292</th>\n      <td>6097</td>\n      <td>hellfire</td>\n      <td>NaN</td>\n      <td>The Prophet (peace be upon him) said 'Save you...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4304</th>\n      <td>6111</td>\n      <td>hellfire</td>\n      <td>NaN</td>\n      <td>The Prophet (peace be upon him) said 'Save you...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4309</th>\n      <td>6118</td>\n      <td>hellfire</td>\n      <td>NaN</td>\n      <td>The Prophet (peace be upon him) said 'Save you...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4318</th>\n      <td>6132</td>\n      <td>hellfire</td>\n      <td>NaN</td>\n      <td>The Prophet (peace be upon him) said 'Save you...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data cleaning\n## remove duplicates with the mean target","metadata":{}},{"cell_type":"code","source":"# get rows with duplicate text\ndf_dup = df[df.duplicated(subset=['text'], keep=False)]\n# replace target for each unqiue text with the average of the targets\ngrouped = df_dup.groupby(\"text\")[\"target\"].transform(\"mean\")\ndf_dup.loc[grouped.index, \"target\"] = grouped\ndf_dup\n# drop duplicates\n#df_dup.drop_duplicates(subset=['text'], keep='first', inplace=True)\n#df_dup\n# replace entries with text equal to df_dup in df with the new target\n\n# for each text in df_dup replace location with the first not nan location from the rows in df with the same text\ndf_dup[\"location\"].fillna(df_dup.groupby(\"text\")[\"location\"].transform(\"first\"), inplace=True)\n\n# replace entries with text equal to df_dup in df with the new target\ndf.loc[df_dup.index, \"target\"] = df_dup[\"target\"]\ndf.loc[df_dup.index, \"location\"] = df_dup[\"location\"]\n# remove duplicates (text) in df\ndf.drop_duplicates(subset=['text'], keep='first', inplace=True)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:04.867861Z","iopub.execute_input":"2023-02-13T13:31:04.868575Z","iopub.status.idle":"2023-02-13T13:31:04.901291Z","shell.execute_reply.started":"2023-02-13T13:31:04.868518Z","shell.execute_reply":"2023-02-13T13:31:04.900305Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return self._update_inplace(result)\n","output_type":"stream"}]},{"cell_type":"code","source":"df[df.text==\"The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'\"]","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:04.902718Z","iopub.execute_input":"2023-02-13T13:31:04.903568Z","iopub.status.idle":"2023-02-13T13:31:04.918812Z","shell.execute_reply.started":"2023-02-13T13:31:04.903528Z","shell.execute_reply":"2023-02-13T13:31:04.917941Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        id   keyword location  \\\n4284  6087  hellfire   Riyadh   \n\n                                                   text    target  \n4284  The Prophet (peace be upon him) said 'Save you...  0.333333  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4284</th>\n      <td>6087</td>\n      <td>hellfire</td>\n      <td>Riyadh</td>\n      <td>The Prophet (peace be upon him) said 'Save you...</td>\n      <td>0.333333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"target\"] = df[\"target\"].round()\ndf[df.text==\"The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'\"]","metadata":{"execution":{"iopub.status.busy":"2023-02-13T13:31:04.920401Z","iopub.execute_input":"2023-02-13T13:31:04.921191Z","iopub.status.idle":"2023-02-13T13:31:04.936141Z","shell.execute_reply.started":"2023-02-13T13:31:04.921141Z","shell.execute_reply":"2023-02-13T13:31:04.935261Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"        id   keyword location  \\\n4284  6087  hellfire   Riyadh   \n\n                                                   text  target  \n4284  The Prophet (peace be upon him) said 'Save you...     0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4284</th>\n      <td>6087</td>\n      <td>hellfire</td>\n      <td>Riyadh</td>\n      <td>The Prophet (peace be upon him) said 'Save you...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ntokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n\n# create iterator from tokenized df\ndef df_iterator_content(df):\n    for _, row in df.iterrows():\n        yield tokenizer(row['text'])\n\nvocab = build_vocab_from_iterator(df_iterator_content(df), specials=[\"<unk>\"], min_freq=5)\nvocab.set_default_index(vocab[\"<unk>\"])\nvocab_size = len(vocab)\nprint(vocab_size)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:04.937477Z","iopub.execute_input":"2023-02-13T13:31:04.937940Z","iopub.status.idle":"2023-02-13T13:31:15.283098Z","shell.execute_reply.started":"2023-02-13T13:31:04.937905Z","shell.execute_reply":"2023-02-13T13:31:15.282016Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"3186\n","output_type":"stream"}]},{"cell_type":"code","source":"def df_iterator_keyword(df):\n    for _, row in df.iterrows():\n        yield tokenizer(row['keyword'])\n\nvocab_keyword = build_vocab_from_iterator(df_iterator_keyword(df), specials=[\"<unk>\"])\nvocab_keyword.set_default_index(vocab_keyword[\"<unk>\"])\nvocab_size_keyword = len(vocab_keyword)\nprint(vocab_size_keyword)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:15.289955Z","iopub.execute_input":"2023-02-13T13:31:15.292608Z","iopub.status.idle":"2023-02-13T13:31:15.911293Z","shell.execute_reply.started":"2023-02-13T13:31:15.292548Z","shell.execute_reply":"2023-02-13T13:31:15.910244Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"223\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass TwitterDisasterDataset(Dataset):\n    def __init__(self, df, word_count=500, vocab_size=10000, train=True):\n        self.df = df\n        self.word_count = word_count\n        self.vocab_size = vocab_size\n        self.train=train\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        text= self.df.iloc[idx][\"text\"]\n        text = vocab(tokenizer(text))\n        if self.train:\n            y= self.df.iloc[idx][\"target\"]\n            y = int(y)\n        if len(text) > self.word_count:\n            text=text[:self.word_count]\n        else:\n            text.extend([0]*(self.word_count-len(text)))\n        text = torch.tensor(text)\n        keyword=self.df.iloc[idx][\"keyword\"]\n        keyword = vocab_keyword(tokenizer(keyword))\n        keyword = torch.tensor(keyword)\n\n        if self.train:\n            return (text.to(device), keyword.to(device)), torch.tensor(y).to(device)\n        else:\n            return (text.to(device), keyword.to(device))\n\ntwitter_dataset = TwitterDisasterDataset(df, word_count=30, vocab_size=vocab_size)\n(text, keyword),y=twitter_dataset[23]\nprint(text)\nprint(keyword)\nprint(y)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:15.913703Z","iopub.execute_input":"2023-02-13T13:31:15.914352Z","iopub.status.idle":"2023-02-13T13:31:23.105743Z","shell.execute_reply.started":"2023-02-13T13:31:15.914314Z","shell.execute_reply":"2023-02-13T13:31:23.104792Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"tensor([137,   5,   0, 119,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0], device='cuda:0')\ntensor([1], device='cuda:0')\ntensor(0, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntorch.manual_seed(1)\n\nclass MyLSTM(nn.Module):\n\n    def __init__(self, text_embedding_dim, text_hidden_dim, vocab_size, out_size, word_count=50, dropout=0.2, num_layers=2, keyword_embedding_dim=16, hidden_layer_size=64):\n        super(MyLSTM, self).__init__()\n        self.hidden_dim = text_hidden_dim\n        self.text_embedding_dim=text_embedding_dim\n        self.text_embeddings = nn.Embedding(vocab_size, text_embedding_dim)\n        self.keyword_embeddings = nn.Embedding(vocab_size, keyword_embedding_dim)\n\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.\n        self.lstm = nn.LSTM(text_embedding_dim, text_hidden_dim, batch_first=True, dropout=dropout, num_layers=num_layers)\n        self.dropout=nn.Dropout(p=dropout)\n\n        self.fc_lstm_to_merge = nn.Linear(text_hidden_dim * word_count, keyword_embedding_dim)\n        self.bn1 = nn.BatchNorm1d(keyword_embedding_dim*2)\n        self.fc_merge_to_hidden = nn.Linear(keyword_embedding_dim*2, hidden_layer_size)\n        self.bn2 = nn.BatchNorm1d(hidden_layer_size)\n        self.fc_hidden_to_out = nn.Linear(hidden_layer_size, out_size)\n\n    def forward(self, text_b, keyword_b, foo=None):\n        #print(\"xb shape\", xb.shape)\n        text_embeds = self.text_embeddings(text_b)\n        #print(\"embeds shape\", text_embeds.shape)\n        lstm_out, _ = self.lstm(text_embeds)\n        lstm_out=self.dropout(lstm_out)\n        #print(\"lstm_out shape\", lstm_out.shape)\n        lstm_out_view = lstm_out.reshape(text_b.shape[0], -1   )\n        #print(\"lstm_out_view shape\", lstm_out_view.shape)\n        lstm_to_merge = self.fc_lstm_to_merge(lstm_out_view)\n        #print(\"lstm_to_merge shape\", lstm_to_merge.shape)\n        keyword_embeds = self.keyword_embeddings(keyword_b)\n        #print(\"keyword_embeds shape\", keyword_embeds.shape)\n        keyword_embeds_view = keyword_embeds.reshape(text_b.shape[0], -1   )\n        #print(\"keyword_embeds_view shape\", keyword_embeds_view.shape)\n        merged = torch.cat((lstm_to_merge, keyword_embeds_view), dim=1)\n        #print(\"merged shape\", merged.shape)\n        merged = self.bn1(merged)\n        merged = F.relu(merged)\n        merged = self.dropout(merged)\n        #print(\"merge shape\", merge.shape)\n        hidden = self.fc_merge_to_hidden(merged)\n        hidden = self.bn2(hidden)\n        hidden = F.relu(hidden)\n        hidden = self.dropout(hidden)\n        output = self.fc_hidden_to_out(hidden)\n        output = F.log_softmax(output, dim=1)\n        #print(\"output shape\", output.shape)\n        return output","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:23.107292Z","iopub.execute_input":"2023-02-13T13:31:23.107675Z","iopub.status.idle":"2023-02-13T13:31:23.120915Z","shell.execute_reply.started":"2023-02-13T13:31:23.107636Z","shell.execute_reply":"2023-02-13T13:31:23.119739Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\ndef evaluate(model, dataloader):\n    model.eval()\n    y_true=[]\n    y_pred=[]\n    with torch.no_grad():\n        for idx, (xb, label) in enumerate(dataloader):\n            text, keyword = xb\n            predicted_label = model(text, keyword)\n            y_true.extend(label.cpu().numpy())\n            y_pred.extend(predicted_label.argmax(1).cpu().numpy())\n    return f1_score(y_true, y_pred)\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:23.122769Z","iopub.execute_input":"2023-02-13T13:31:23.123314Z","iopub.status.idle":"2023-02-13T13:31:23.132010Z","shell.execute_reply.started":"2023-02-13T13:31:23.123280Z","shell.execute_reply":"2023-02-13T13:31:23.131028Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter\nembed_dim = 128\nnum_class = 2\nhidden_dim = 64\nword_count = 50\nEPOCHS = 10 # epoch\nLR = 0.01  # learning rate\nscheduler_patience=4\nscheduler_factor=0.2\nweight_decay=1e-4\nBATCH_SIZE = 64 # batch size for training\ndropout=0.7\nnum_layers=2\nhidden_layer_size=64\nkeyword_embedding_dim=16\n\n\n# check if model works\nmodel= MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout, num_layers=num_layers, hidden_layer_size=hidden_layer_size, keyword_embedding_dim=keyword_embedding_dim).to(device)\ndataset = TwitterDisasterDataset(df, word_count=word_count, vocab_size=vocab_size)\nloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n\n(text, keyword), yb = next(iter(loader))\nprint(\"yb\", yb)\nprint(\"xb text shape\", text.shape)\nprint(\"xb keyword shape\", keyword.shape)\nmodel(text, keyword)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:23.133425Z","iopub.execute_input":"2023-02-13T13:31:23.134416Z","iopub.status.idle":"2023-02-13T13:31:24.790574Z","shell.execute_reply.started":"2023-02-13T13:31:23.134377Z","shell.execute_reply":"2023-02-13T13:31:24.789563Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"yb tensor([1, 0, 1, 0, 0], device='cuda:0')\nxb text shape torch.Size([5, 50])\nxb keyword shape torch.Size([5, 1])\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor([[-1.2455, -0.3394],\n        [-0.5572, -0.8506],\n        [-1.6572, -0.2116],\n        [-0.4055, -1.0986],\n        [-0.7050, -0.6815]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# torch.onnx.export(model, (text, keyword), \"model.onnx\", input_names=[\"text\", \"keyword\"], output_names=[\"y_hat\"], verbose=True, opset_version=11)\n\n# visualize model with netron.app","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:31:24.792177Z","iopub.execute_input":"2023-02-13T13:31:24.792544Z","iopub.status.idle":"2023-02-13T13:31:24.796842Z","shell.execute_reply.started":"2023-02-13T13:31:24.792509Z","shell.execute_reply":"2023-02-13T13:31:24.795857Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# hyperparameter search\n\nparam_grid = {\n    \"embed_dim\": [32, 64, 128],\n    \"hidden_dim\": [64, 32, 128],\n    \"dropout\": [0.4, 0.5, 0.7],\n    \"num_layers\": [2, 4],\n    \"weight_decay\": [1e-6],\n    \"LR\": [0.01],\n    \"BATCH_SIZE\": [128, 256],\n    \"hidden_layer_size\": [64],\n    \"keyword_embedding_dim\": [32],\n    \"word_count\": [50]\n}\n\nparam_grid = ParameterGrid(param_grid)\nprint(next(iter(param_grid)))\nprint(len(param_grid))","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:33:57.125828Z","iopub.execute_input":"2023-02-13T13:33:57.126893Z","iopub.status.idle":"2023-02-13T13:33:57.135264Z","shell.execute_reply.started":"2023-02-13T13:33:57.126853Z","shell.execute_reply":"2023-02-13T13:33:57.133983Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"{'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50}\n108\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef grid_search():\n\n    params_count={}\n    for params in param_grid:\n        for key, value in params.items():\n            param_str=key+\":\"+str(value)\n            if param_str not in params_count:\n                params_count[param_str]=1\n            else:\n                params_count[param_str]+=1\n    EPOCHS=10\n\n    # set all random seeds\n    torch.manual_seed(1)\n    np.random.seed(1)\n\n    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    (gridsearch_portion_idx, test_idx) = next(iter(k_fold.split(df[\"text\"], df[\"target\"])))\n    grid_test_df=df.iloc[test_idx]\n    gridsearch_df=df.iloc[gridsearch_portion_idx]\n    test_dataset=TwitterDisasterDataset(grid_test_df, word_count=word_count, vocab_size=vocab_size)\n    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    k_fold_iter=iter(k_fold.split(gridsearch_df[\"text\"], gridsearch_df[\"target\"]))\n    (base_idx, split_portion_idx)=next(k_fold_iter)\n    base_df = df.iloc[base_idx]\n    split_portion_df = df.iloc[split_portion_idx]\n    train_dataset = TwitterDisasterDataset(split_portion_df, word_count=word_count, vocab_size=vocab_size)\n    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n    i=0\n    best_params_val=0\n    best_params=None\n    params_results={}\n    for params in param_grid:\n        i+=1\n        model = MyLSTM(params[\"embed_dim\"], params[\"hidden_dim\"], vocab_size, num_class, word_count=word_count, dropout=params[\"dropout\"], num_layers=params[\"num_layers\"]).to(device)\n        loss_func = torch.nn.CrossEntropyLoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=params[\"LR\"], weight_decay=params[\"weight_decay\"])\n        for epoch in range(EPOCHS):\n            model.train()\n            for idx, (xb, label) in enumerate(train_dataloader):\n                text, keyword = xb\n                predicted_label = model(text, keyword)\n                loss = loss_func(predicted_label, label)\n                optimizer.zero_grad()\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n                optimizer.step()\n        test_f1 = evaluate(model, test_dataloader)\n        print(f\"{i} / {len(param_grid)} params {params} Test f1 {test_f1}\")\n        with open(\"results.txt\", \"a\") as f:\n            f.write(f\"{i}: params {params} test f1 {test_f1} \\n\")\n        if test_f1 > best_params_val:\n            best_params_val = test_f1\n            best_params = params\n        for key, value in params.items():\n            param_str=key+\":\"+str(value)\n            if param_str not in params_results:\n                params_results[param_str]=test_f1\n            else:\n                params_results[param_str]+=test_f1\n\n    for key, value in params_results.items():\n        params_results[key]=params_results[key]/params_count[key]\n    return best_params, best_params_val, params_results\n\nbest_params, best_params_val, params_results = grid_search()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:34:03.707086Z","iopub.execute_input":"2023-02-13T13:34:03.707468Z","iopub.status.idle":"2023-02-13T13:45:14.396263Z","shell.execute_reply.started":"2023-02-13T13:34:03.707433Z","shell.execute_reply":"2023-02-13T13:45:14.394436Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"1 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6579378068739771\n2 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4851851851851851\n3 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6247818499127399\n4 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5190311418685121\n5 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5561497326203209\n6 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.42171189979123175\n7 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.601449275362319\n8 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4273858921161826\n9 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6373292867981789\n10 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6579973992197659\n11 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6208112874779542\n12 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.47755834829443444\n13 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.612736660929432\n14 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5315985130111524\n15 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6666666666666666\n16 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5140562248995985\n17 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6098003629764065\n18 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.505307855626327\n19 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.36320754716981135\n20 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.13850415512465375\n21 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.650137741046832\n22 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.46181818181818185\n23 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5901060070671378\n24 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.3902439024390244\n25 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4539877300613497\n26 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5239005736137667\n27 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6027397260273972\n28 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5494505494505495\n29 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6666666666666667\n30 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.3991323210412147\n31 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6582278481012658\n32 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6648936170212766\n33 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6788990825688074\n34 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4355179704016914\n35 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6031746031746031\n36 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6454689984101749\n37 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n38 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n39 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n40 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n41 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n42 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n43 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.01238390092879257\n44 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n45 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n46 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.06547619047619048\n47 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6331428571428571\n48 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n49 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.47357293868921774\n50 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n51 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.02469135802469136\n52 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n53 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4025157232704403\n54 / 108 params {'BATCH_SIZE': 128, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.053731343283582096\n55 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5659050966608085\n56 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5276461295418642\n57 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6638772663877267\n58 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5997638724911453\n59 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5915789473684212\n60 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5087108013937282\n61 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6496240601503759\n62 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.3824175824175824\n63 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6596701649175413\n64 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5018181818181818\n65 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6054054054054054\n66 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.43737574552683894\n67 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6360424028268551\n68 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.46511627906976744\n69 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6638537271448665\n70 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6798866855524079\n71 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.556390977443609\n72 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.4, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4708097928436912\n73 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4937759336099585\n74 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.37288135593220345\n75 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5420875420875421\n76 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.550185873605948\n77 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5276752767527676\n78 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.21393034825870647\n79 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5595463137996219\n80 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5739750445632799\n81 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6263910969793323\n82 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.15760869565217392\n83 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4618556701030928\n84 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.3448275862068965\n85 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6196213425129088\n86 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5178294573643412\n87 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.670750382848392\n88 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.4482758620689655\n89 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.6424418604651163\n90 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.5, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.2997658079625292\n91 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n92 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n93 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.006211180124223602\n94 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n95 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n96 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 32, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.06547619047619048\n97 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.13370473537604458\n98 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n99 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.08849557522123892\n100 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n101 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.018518518518518517\n102 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 64, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0771513353115727\n103 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.07624633431085044\n104 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 64, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.018518518518518517\n105 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n106 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 32, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.0\n107 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 2, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.5831903945111493\n108 / 108 params {'BATCH_SIZE': 256, 'LR': 0.01, 'dropout': 0.7, 'embed_dim': 128, 'hidden_dim': 128, 'hidden_layer_size': 64, 'keyword_embedding_dim': 32, 'num_layers': 4, 'weight_decay': 1e-06, 'word_count': 50} Test f1 0.006230529595015576\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params, best_params_val","metadata":{"execution":{"iopub.status.busy":"2023-02-13T13:45:39.294302Z","iopub.execute_input":"2023-02-13T13:45:39.294720Z","iopub.status.idle":"2023-02-13T13:45:39.301783Z","shell.execute_reply.started":"2023-02-13T13:45:39.294685Z","shell.execute_reply":"2023-02-13T13:45:39.300682Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"({'BATCH_SIZE': 256,\n  'LR': 0.01,\n  'dropout': 0.4,\n  'embed_dim': 128,\n  'hidden_dim': 32,\n  'hidden_layer_size': 64,\n  'keyword_embedding_dim': 32,\n  'num_layers': 4,\n  'weight_decay': 1e-06,\n  'word_count': 50},\n 0.6798866855524079)"},"metadata":{}}]},{"cell_type":"code","source":"params_results","metadata":{"execution":{"iopub.status.busy":"2023-02-13T13:45:49.423861Z","iopub.execute_input":"2023-02-13T13:45:49.424316Z","iopub.status.idle":"2023-02-13T13:45:49.432439Z","shell.execute_reply.started":"2023-02-13T13:45:49.424276Z","shell.execute_reply":"2023-02-13T13:45:49.431234Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'BATCH_SIZE:128': 0.3938719800490844,\n 'LR:0.01': 0.3808532296698932,\n 'dropout:0.4': 0.5637052363497557,\n 'embed_dim:32': 0.33579224904469007,\n 'hidden_dim:64': 0.36660617307898236,\n 'hidden_layer_size:64': 0.3808532296698932,\n 'keyword_embedding_dim:32': 0.3808532296698932,\n 'num_layers:2': 0.4452588308348932,\n 'weight_decay:1e-06': 0.3808532296698932,\n 'word_count:50': 0.3808532296698932,\n 'num_layers:4': 0.31644762850489344,\n 'hidden_dim:32': 0.38742970766887463,\n 'hidden_dim:128': 0.38852380826182303,\n 'embed_dim:64': 0.37799438101792554,\n 'embed_dim:128': 0.4287730589470644,\n 'dropout:0.5': 0.5027639631105051,\n 'dropout:0.7': 0.07609048954941927,\n 'BATCH_SIZE:256': 0.36783447929070223}"},"metadata":{}}]},{"cell_type":"code","source":"hyperparams = {'BATCH_SIZE': 256,\n  'LR': 0.01,\n  'dropout': 0.4,\n  'embed_dim': 128,\n  'hidden_dim': 32,\n  'hidden_layer_size': 64,\n  'keyword_embedding_dim': 32,\n  'num_layers': 4,\n  'weight_decay': 1e-06,\n  'word_count': 50}\n\n\nBATCH_SIZE=hyperparams[\"BATCH_SIZE\"]\nLR = hyperparams[\"LR\"]\nembed_dim = hyperparams[\"embed_dim\"]\nhidden_dim = hyperparams[\"hidden_dim\"]\nnum_layers = hyperparams[\"num_layers\"]\nweight_decay = hyperparams[\"weight_decay\"]\nword_count = hyperparams[\"word_count\"]\nhidden_layer_size=hyperparams[\"hidden_layer_size\"]\nkeyword_embedding_dim=hyperparams[\"keyword_embedding_dim\"]\nEPOCHS = 7\nscheduler_patience=4\nscheduler_factor=0.2","metadata":{"execution":{"iopub.status.busy":"2023-02-13T13:53:46.107269Z","iopub.execute_input":"2023-02-13T13:53:46.107664Z","iopub.status.idle":"2023-02-13T13:53:46.115220Z","shell.execute_reply.started":"2023-02-13T13:53:46.107629Z","shell.execute_reply":"2023-02-13T13:53:46.114125Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"\n# create train and valid dataset\ntrain_dataset, valid_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n\n# import torch DataLoader\nfrom torch.utils.data import DataLoader\n\nmodel = MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout, keyword_embedding_dim=keyword_embedding_dim, hidden_layer_size=hidden_layer_size ).to(device)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=weight_decay)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_step_size, gamma=lr_gamma)   # every 10 epochs, LR is multiplied by 0.7\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=scheduler_factor, patience=scheduler_patience)\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:53:46.410640Z","iopub.execute_input":"2023-02-13T13:53:46.412892Z","iopub.status.idle":"2023-02-13T13:53:46.430139Z","shell.execute_reply.started":"2023-02-13T13:53:46.412845Z","shell.execute_reply":"2023-02-13T13:53:46.429169Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"total_accu = None\ntrain_accus=[]\nvalid_accus=[]\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n\n    model.train()\n    total_acc, total_count = 0, 0\n\n    for idx, (xb, label) in enumerate(train_dataloader):\n        text, keyword = xb\n        optimizer.zero_grad()\n        predicted_label = model(text, keyword)\n        loss = loss_func(predicted_label, label)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n\n    accu_train = evaluate(model, train_dataloader)\n    accu_valid = evaluate(model, valid_dataloader)\n    train_accus.append(accu_train)\n    valid_accus.append(accu_valid)\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | train f1 {:8.3f} | valid f1 {:8.3f} | lr: {:1.5f}'.format(\n        epoch,\n        time.time() - epoch_start_time,\n        accu_train,\n        accu_valid,\n        optimizer.param_groups[0]['lr']))\n\n    scheduler.step(accu_valid) # learning rate scheduler after each epoch\n\nplt.plot(train_accus, label='train_accu')\nplt.plot(valid_accus, label='valid_accu')\nplt.legend()\nplt.show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:53:46.662808Z","iopub.execute_input":"2023-02-13T13:53:46.663112Z","iopub.status.idle":"2023-02-13T13:54:54.064790Z","shell.execute_reply.started":"2023-02-13T13:53:46.663076Z","shell.execute_reply":"2023-02-13T13:54:54.063781Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"-----------------------------------------------------------\n| end of epoch   1 | time:  9.62s | train f1    0.477 | valid f1    0.478 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   2 | time:  9.54s | train f1    0.133 | valid f1    0.113 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   3 | time:  9.47s | train f1    0.732 | valid f1    0.670 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   4 | time:  9.90s | train f1    0.840 | valid f1    0.751 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   5 | time:  9.25s | train f1    0.870 | valid f1    0.737 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   6 | time:  9.49s | train f1    0.911 | valid f1    0.750 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   7 | time:  9.93s | train f1    0.931 | valid f1    0.717 | lr: 0.01000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"df_test = pd.read_csv(test_csv)\ndf_test[\"keyword\"].fillna(\"None\", inplace=True)\ndf_test.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:48:41.914953Z","iopub.execute_input":"2023-02-13T13:48:41.915937Z","iopub.status.idle":"2023-02-13T13:48:41.937804Z","shell.execute_reply.started":"2023-02-13T13:48:41.915888Z","shell.execute_reply":"2023-02-13T13:48:41.936540Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0    None      NaN                 Just happened a terrible car crash\n1   2    None      NaN  Heard about #earthquake is different cities, s...\n2   3    None      NaN  there is a forest fire at spot pond, geese are...\n3   9    None      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11    None      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset = TwitterDisasterDataset(df_test, word_count=word_count, vocab_size=vocab_size, train=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n\npredictions=[]\nmodel.eval()\nwith torch.no_grad():\n    for idx, xb in enumerate(test_dataloader):\n        text, keyword = xb\n        predicted_label = model(text, keyword)\n        predictions.append(predicted_label.argmax(1).cpu().numpy())\n        \n\npredictions=np.concatenate(predictions)\nprint(predictions.shape)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:48:42.459070Z","iopub.execute_input":"2023-02-13T13:48:42.459829Z","iopub.status.idle":"2023-02-13T13:48:45.174135Z","shell.execute_reply.started":"2023-02-13T13:48:42.459789Z","shell.execute_reply":"2023-02-13T13:48:45.172809Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"(3263,)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_submission = pd.read_csv(submission_csv)\ndf_submission[\"target\"] = predictions\ndf_submission.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:48:45.180018Z","iopub.execute_input":"2023-02-13T13:48:45.182890Z","iopub.status.idle":"2023-02-13T13:48:45.204918Z","shell.execute_reply.started":"2023-02-13T13:48:45.182839Z","shell.execute_reply":"2023-02-13T13:48:45.203804Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       1\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_submission.to_csv(\"submission.csv\", index=False)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-13T13:48:45.210064Z","iopub.execute_input":"2023-02-13T13:48:45.212850Z","iopub.status.idle":"2023-02-13T13:48:45.230309Z","shell.execute_reply.started":"2023-02-13T13:48:45.212804Z","shell.execute_reply":"2023-02-13T13:48:45.229071Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}